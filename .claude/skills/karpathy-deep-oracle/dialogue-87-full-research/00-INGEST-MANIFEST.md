# Dialogue 87: Full Research Ingest Manifest

## ALL 100 QUERIES → KARPATHY ORACLE

**Purpose:** Inject geometric precision into the Spicy Lentil Taco Burger architecture
**Source:** Dialogue 87 - Grasping Back and Imagining Forward

---

## Research Batches (10 queries each)

### BATCH 1: GPU Texture Memory (Queries 1-10)
**File:** `01-gpu-texture-memory.md` (content exists in gpu-texture-optimization/)
**Status:** [✅] COMPLETE - 2000+ lines in existing oracle files

### BATCH 2: VLM Attention Injection (Queries 11-20)
**File:** `02-vlm-attention-injection.md`
**Status:** [✅] COMPLETE - LLaVA, Q-Former, FiLM documented

### BATCH 3: Token Budget Allocation (Queries 21-30)
**File:** `03-token-budget-allocation.md`
**Status:** [✅] COMPLETE - ToMe, dynamic tokens, budgets

### BATCH 4: Learned Channel Weighting (Queries 31-40)
**File:** `04-channel-weighting-senet-film.md`
**Status:** [✅] COMPLETE - SENet (46k citations!), FiLM, ECA

### BATCH 5: GNN Cognitive Fingerprint (Queries 41-50)
**File:** `05-gnn-cognitive-fingerprint.md`
**Status:** [✅] COMPLETE - GAT, GraphSAGE, hetero GNNs

### BATCH 6: Quorum Sensing Bioelectric (Queries 51-60)
**File:** `06-quorum-sensing-bioelectric.md`
**Status:** [✅] COMPLETE - AHL threshold, Levin bioelectric

### BATCH 7: Attention Null Point Synthesis (Queries 61-70)
**File:** `07-attention-null-point.md`
**Status:** [✅] COMPLETE - MoE, gated fusion, Shinjuku pattern

### BATCH 8: 3D Mesh Features (Queries 71-80)
**File:** `08-mesh-features-3d.md`
**Status:** [✅] COMPLETE - PointNet (22k citations!), curvature, genus

### BATCH 9: Cache/Fresh Blending (Queries 81-90)
**File:** `09-cache-fresh-blending.md`
**Status:** [✅] COMPLETE - Thompson sampling, RAG, staleness

### BATCH 10: Multi-Pass Processing (Queries 91-100)
**File:** `10-multipass-refinement.md`
**Status:** [✅] COMPLETE - Coarse-to-fine, RAFT, cascades

---

## The 100 Queries

### BATCH 1: GPU TEXTURE MEMORY (1-10)

1. "GPU texture cache vs L1 cache difference performance"
2. "CUDA texture memory 2D array optimal access patterns"
3. "Morton Z-order memory layout GPU textures"
4. "OpenGL texture fetch latency vs tensor operations"
5. "1x1 convolution GPU parallelism optimization"
6. "Hardware texture interpolation bilinear CUDA"
7. "Texture memory bandwidth vs global memory bandwidth GPU"
8. "GPU texture cache hierarchy architecture"
9. "Sparse texture storage compression GPU"
10. "Multi-channel texture array batch processing CUDA"

### BATCH 2: VLM ATTENTION INJECTION (11-20)

11. "LLaVA cross attention architecture layers"
12. "Vision transformer attention bias injection methods"
13. "Multimodal attention in vision-language models"
14. "Per-layer attention bias learning transformers"
15. "Cross-modal attention modulation VLMs"
16. "Attention prior injection neural networks"
17. "Soft attention bias vs hard token selection VQA"
18. "LLaVA-1.5 architecture diagram cross attention"
19. "Flamingo perceiver attention injection"
20. "BLIP-2 Q-Former attention mechanism"

### BATCH 3: TOKEN BUDGET ALLOCATION (21-30)

21. "Variable length vision tokens VLM efficiency"
22. "Token budget allocation visual question answering"
23. "Adaptive token pruning vision transformers"
24. "Dynamic token selection differentiable"
25. "Token merging ToMe vision transformers"
26. "Patch selection attention VQA"
27. "Resource allocation neural networks constrained"
28. "Token budget prediction loss function"
29. "LLaVA token efficiency different resolutions"
30. "Visual token compression VLM context window"

### BATCH 4: LEARNED CHANNEL WEIGHTING (31-40)

31. "Learned feature channel weighting neural networks"
32. "Channel attention mechanism squeeze excitation"
33. "Query-conditioned feature selection"
34. "Feature importance learning deep learning"
35. "Channel recalibration networks"
36. "Soft attention over feature channels"
37. "FiLM feature-wise linear modulation"
38. "Hypernetworks for channel weighting"
39. "Query-adaptive feature fusion multimodal"
40. "Channel-wise attention visual question answering"

### BATCH 5: GNN COGNITIVE FINGERPRINT (41-50)

41. "Graph neural network message passing tutorial"
42. "GNN for knowledge graph reasoning"
43. "Graph attention networks GAT implementation"
44. "Heterogeneous graph neural networks"
45. "GraphSAGE inductive learning"
46. "Graph convolutional network GCN PyTorch"
47. "Node embedding graph neural networks"
48. "Dynamic graph neural networks temporal"
49. "GNN aggregation functions comparison"
50. "Personal knowledge graph neural network"

### BATCH 6: QUORUM SENSING BIOELECTRIC (51-60)

51. "Quorum sensing bacteria collective decision"
52. "Bioelectric networks Michael Levin computation"
53. "Gap junction bioelectric signaling"
54. "Collective intelligence bioelectric morphogenesis"
55. "Voltage gradient pattern formation biology"
56. "Bacterial quorum sensing threshold mechanism"
57. "Neural synchronization gamma oscillations quorum"
58. "Bioelectric code cellular computation"
59. "Levin xenobots collective behavior"
60. "Morphological computation bioelectric fields"

### BATCH 7: ATTENTION NULL POINT SYNTHESIS (61-70)

61. "Multi-head attention fusion mechanisms"
62. "Gated multimodal fusion deep learning"
63. "Attention-based feature aggregation"
64. "Learned fusion weights neural network"
65. "Mixture of experts attention gating"
66. "Cross-modal attention pooling"
67. "Self-attention aggregation multiple streams"
68. "Weighted combination learnable attention"
69. "Feature fusion interpretable attention"
70. "Multi-pathway neural network attention"

### BATCH 8: 3D MESH FEATURES (71-80)

71. "Mesh curvature computation discrete geometry"
72. "Genus computation mesh topology"
73. "3D shape descriptors deep learning"
74. "Mesh complexity metrics computer graphics"
75. "Surface normal computation 3D reconstruction"
76. "Point cloud to mesh feature extraction"
77. "PointNet mesh feature learning"
78. "3D object slot attention SLOTS"
79. "Mesh-based neural network architecture"
80. "Geometric deep learning mesh representation"

### BATCH 9: CACHE/FRESH BLENDING (81-90)

81. "Adaptive cache hit rate optimization"
82. "Memory consolidation retrieval learning"
83. "Exploration exploitation trade-off adaptive"
84. "Confidence-weighted ensemble neural networks"
85. "Prior-likelihood blending Bayesian"
86. "Knowledge transfer online learning"
87. "Cache miss prediction machine learning"
88. "Retrieval augmented generation blending"
89. "Staleness freshness tradeoff machine learning"
90. "Adaptive mixture weight learning"

### BATCH 10: MULTI-PASS PROCESSING (91-100)

91. "Coarse to fine processing vision"
92. "Multi-pass refinement neural networks"
93. "Iterative attention refinement"
94. "Cascade detection coarse to fine"
95. "Recurrent refinement visual reasoning"
96. "Progressive neural network processing"
97. "Multi-scale temporal processing attention"
98. "Saccade sequence planning computational"
99. "Iterative inference neural networks"
100. "Refinement networks visual question answering"

---

## Execution Plan

Run oracle-knowledge-runner for each batch:
```
BATCH 1 → 01-gpu-texture-memory.md
BATCH 2 → 02-vlm-attention-injection.md
...
BATCH 10 → 10-multipass-refinement.md
```

All results go into: `.claude/skills/karpathy-deep-oracle/dialogue-87-full-research/`

---

## Expected Outcome

After all 10 batches complete:
- 10 research files with ~50-100KB each
- ~500-1000KB total knowledge injection
- GEOMETRIC PRECISION on all Dialogue 86-87 claims!

**THE ORACLES WILL KNOW WHAT THEY'RE TALKING ABOUT!!**
