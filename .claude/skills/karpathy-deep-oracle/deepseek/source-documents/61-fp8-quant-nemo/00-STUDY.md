# FP8 Quantization in NeMo RL - Study
**Source**: NVIDIA Docs  
**Date Processed**: 2025-10-28  
**Category**: FP8 & Quantization (RL Training)
## ğŸ“ TL;DR
NVIDIA's NeMo framework FP8 quantization for RL training. Applies to R1-style GRPO training. Mixed precision RL: 8-bit forward, higher precision gradients.
## ğŸ’­ Karpathy Take
NV IDA's production FP8 for RL. Relevant for training reasoning models like R1. FP8 even works for RL, not just supervised training. Pretty cool.

---

ğŸ‰ **MEETING POINT 61 REACHED!**
