# V3 & R1 Architecture (Fireworks) - Study
**Source**: Fireworks AI  
**Date Processed**: 2025-10-28  
**Category**: DeepSeek Models (Architecture Overview)
## ğŸ“ TL;DR
Fireworks AI's take on V3/R1 architecture. Why powerful (MLA+MoE) and economical (FP8+$5.5M). Deployment perspective from inference provider.
## ğŸ’­ Karpathy Take
Inference provider's view. Fireworks runs these models, so they care about efficiency. MLA matters for serving costs.
