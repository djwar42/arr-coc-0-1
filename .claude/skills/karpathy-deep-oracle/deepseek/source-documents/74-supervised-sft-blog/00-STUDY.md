# Supervised Fine-Tuning From Scratch - Study

**Source**: Blog (Supervised Fine Tuning From Scratch | Liyuan's Log - GitHub Pages)
**Date Processed**: 2025-10-29
**Category**: LOW - General SFT Tutorial

---

## ğŸ“ TL;DR

Blog post on SFT fundamentals from scratch. General tutorial, not DeepSeek-specific. Covers data prep, loss functions, hyperparameters, evaluation. Useful for understanding SFT basics but not directly about DeepSeek's methods.

---

## ğŸ”— Connections

- **04-deepseek-r1-paper**: R1 uses cold-start SFT before RL
- **16-esft-marktech**: Expert-specialized SFT for MoE

---

## ğŸ’­ Karpathy Take

General SFT tutorial. Not DeepSeek-specific but useful background. SFT = take pretrained model + supervised examples â†’ optimize cross-entropy loss. Standard ML stuff. The interesting part for DeepSeek is ESFT (expert-specialized) and multi-stage training, not basic SFT.
