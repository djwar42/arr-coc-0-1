# Quantization - Hugging Face Docs - Study

**Source**: Hugging Face (Quantization documentation)
**Date Processed**: 2025-10-29
**Category**: LOW - General Quantization Guide

---

## ğŸ“ TL;DR

HuggingFace's general quantization documentation. Covers INT8, FP8, GPTQ, bitsandbytes, etc. Not DeepSeek-specific - general guide for quantizing models in Transformers library. Useful reference but not about DeepSeek's innovations.

---

## ğŸ”— Connections

- **05-fp8-lm-paper**: DeepSeek's FP8 approach
- **10-fine-grained-fp8**: Fine-grained FP8 quantization

---

## ğŸ’­ Karpathy Take

General HF docs. Good for "how do I quantize my model in Transformers?" Not about DeepSeek's training-time FP8 or novel techniques. Standard quantization cookbook stuff.
