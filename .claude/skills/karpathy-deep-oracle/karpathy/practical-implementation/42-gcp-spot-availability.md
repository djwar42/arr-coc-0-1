# GCP Spot Instance Regional Availability & Capacity Planning

**Complete guide to Spot VM availability patterns, regional analysis, and capacity planning strategies for production ML training**

---

## Overview

Spot instance availability on Google Cloud Platform varies significantly by region, zone, and resource type. Understanding these patterns is critical for building reliable, cost-optimized ML training infrastructure. This guide provides comprehensive analysis of spot availability patterns and strategies for capacity planning.

**Key Insight:** Spot VMs rely on surplus capacity - availability fluctuates based on overall GCP usage. Success requires multi-zone, multi-region strategies with automated failover.

---

## Section 1: Regional Availability Patterns

### Understanding GCP Spot Capacity Distribution

Spot VMs are excess Compute Engine capacity offered at steep discounts (60-91%). Their availability depends on:

1. **Regional demand patterns** - Data center utilization varies by region
2. **Time-based fluctuations** - Capacity changes throughout the day
3. **Zone-level variations** - Individual zones have different capacity profiles
4. **GPU/TPU scarcity** - Accelerator availability more constrained than CPU

**Critical Rule:** Spot VMs have NO availability guarantees. They can be preempted at any time with 30-second notice.

From [GCP Spot VMs Documentation](https://docs.cloud.google.com/compute/docs/instances/spot) (accessed 2025-01-31):
- Spot VMs are excess capacity - availability varies with Compute Engine usage
- No minimum or maximum runtime unless manually configured
- Can be preempted at any time when capacity is needed
- Separate quota from on-demand instances

### Top Regions for Spot Availability

Based on infrastructure analysis and regional capacity patterns:

#### 1. us-central1 (Iowa, USA)

**Overall Assessment:** Highest spot availability for most workloads

**Strengths:**
- Large data center footprint with high capacity
- Good GPU availability (A100, L4, T4)
- H100 availability (limited zones: us-central1-a, us-central1-b)
- TPU v4, v5e availability
- Excellent for US-based ML training

**Zones:**
- us-central1-a: High availability, H100 available
- us-central1-b: High availability, H100 available
- us-central1-c: High availability, standard GPUs
- us-central1-f: High availability, standard GPUs

**Best For:** Large-scale training, multi-GPU workloads, TPU training

From [GCP Regions Documentation](https://docs.cloud.google.com/compute/docs/regions-zones) (accessed 2025-01-31):
- Recommended for fault-tolerant applications requiring high availability
- Deploy across multiple zones for redundancy
- us-central1 is one of GCP's largest regions

#### 2. us-west1 (Oregon, USA)

**Overall Assessment:** Good spot availability with lower latency to West Coast

**Strengths:**
- Solid capacity for CPU-based spot instances
- Good L4, T4 GPU availability
- Limited A100/H100 availability (check specific zones)
- Lower network latency for West Coast users

**Zones:**
- us-west1-a: Good availability
- us-west1-b: Good availability
- us-west1-c: Moderate availability

**Best For:** West Coast workloads, L4-based inference, data preprocessing

#### 3. us-east1 (South Carolina, USA)

**Overall Assessment:** High availability with good GPU selection

**Strengths:**
- Large data center capacity
- A100 availability in multiple zones
- TPU availability (v4, v5e)
- Good for East Coast low-latency requirements

**Zones:**
- us-east1-b: High availability
- us-east1-c: High availability
- us-east1-d: High availability

**Best For:** East Coast training, A100 workloads, TPU training

#### 4. europe-west4 (Netherlands)

**Overall Assessment:** Primary European region for ML workloads

**Strengths:**
- Highest European spot availability
- A100 availability
- H100 availability (limited zones)
- TPU v4 availability
- Best for EU data residency requirements

**Zones:**
- europe-west4-a: High availability, H100 available
- europe-west4-b: High availability
- europe-west4-c: High availability

**Best For:** European ML training, GDPR compliance, A100/H100 workloads

From [Cast.AI GPU Report 2025](https://cast.ai/reports/gpu-price-2025/) (accessed 2025-01-31):
- H100 availability concentrated in us-central1 and europe-west4
- A100 availability widespread across major regions
- Regional pricing varies 10-20% based on capacity

#### 5. asia-southeast1 (Singapore)

**Overall Assessment:** Primary APAC hub for spot instances

**Strengths:**
- Good spot availability for APAC region
- A100 availability
- L4, T4 GPU availability
- Lower latency for Asian customers

**Zones:**
- asia-southeast1-a: Good availability
- asia-southeast1-b: Good availability
- asia-southeast1-c: Moderate availability

**Best For:** APAC ML training, regional data residency, A100 workloads

### Regions with Limited Spot Availability

**Newer/Smaller Regions:**
- us-west2, us-west3, us-west4: Limited GPU availability
- europe-west2, europe-west3: Lower spot capacity than west4
- asia-northeast1, asia-northeast2: Moderate capacity, check GPU availability
- Middle East, Africa regions: Limited spot offerings

**Strategy:** Use these regions only for specific data residency requirements, not primary training.

### Regional Availability Heatmap

```
REGION AVAILABILITY MATRIX (Spot VMs)
=====================================

Region              | CPU Spot | A100  | H100  | L4   | TPU v4 | Rating
--------------------|----------|-------|-------|------|--------|--------
us-central1 (Iowa)  | â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | â–ˆâ–ˆâ–ˆâ–ˆ  | â–ˆâ–ˆâ–ˆ   | â–ˆâ–ˆâ–ˆâ–ˆ | â–ˆâ–ˆâ–ˆâ–ˆ   | â˜…â˜…â˜…â˜…â˜…
us-east1 (S.Car)    | â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | â–ˆâ–ˆâ–ˆ   | â–ˆâ–ˆ    | â–ˆâ–ˆâ–ˆ  | â–ˆâ–ˆâ–ˆâ–ˆ   | â˜…â˜…â˜…â˜…â˜†
us-west1 (Oregon)   | â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | â–ˆâ–ˆ    | â–ˆ     | â–ˆâ–ˆâ–ˆâ–ˆ | â–ˆâ–ˆâ–ˆ    | â˜…â˜…â˜…â˜†â˜†
europe-west4 (NL)   | â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | â–ˆâ–ˆâ–ˆ   | â–ˆâ–ˆ    | â–ˆâ–ˆâ–ˆ  | â–ˆâ–ˆâ–ˆâ–ˆ   | â˜…â˜…â˜…â˜…â˜†
asia-southeast1     | â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | â–ˆâ–ˆ    | â–ˆ     | â–ˆâ–ˆâ–ˆ  | â–ˆâ–ˆ     | â˜…â˜…â˜…â˜†â˜†

Legend: â–ˆâ–ˆâ–ˆâ–ˆ = High    â–ˆâ–ˆâ–ˆ = Good    â–ˆâ–ˆ = Limited    â–ˆ = Rare
```

From [GCP GPU Regions Documentation](https://docs.cloud.google.com/compute/docs/gpus/gpu-regions-zones) (accessed 2025-01-31):
- GPU availability varies by region and zone
- A3 machines (H100) available in limited regions
- G2 machines (L4) widespread availability
- Check real-time availability via gcloud commands

---

## Section 2: GPU/TPU Availability Analysis

### GPU Spot Availability by Type

#### NVIDIA A100 (Most Widely Available)

**Regional Availability:**

**High Availability Regions:**
- us-central1 (multiple zones)
- us-east1 (multiple zones)
- europe-west4 (multiple zones)
- asia-southeast1 (limited zones)

**Machine Types:**
- a2-highgpu-1g (1x A100 40GB)
- a2-highgpu-2g (2x A100 40GB)
- a2-highgpu-4g (4x A100 40GB)
- a2-highgpu-8g (8x A100 40GB)
- a2-megagpu-16g (16x A100 40GB)
- a2-ultragpu-1g (1x A100 80GB)
- a2-ultragpu-2g (2x A100 80GB)
- a2-ultragpu-4g (4x A100 80GB)
- a2-ultragpu-8g (8x A100 80GB)

**Spot Availability Patterns:**
- Best availability: 1-2 GPU instances (a2-highgpu-1g, a2-highgpu-2g)
- Moderate availability: 4-8 GPU instances
- Limited availability: 16 GPU instances (a2-megagpu-16g)

**Strategy:** Start with smaller instance sizes, scale up as needed. Multi-zone deployment essential for 8+ GPU training.

#### NVIDIA H100 (Limited Availability)

**Regional Availability:**

**Available Regions (H100 80GB):**
- us-central1-a
- us-central1-b
- europe-west4-a

**Machine Types (A3 series):**
- a3-highgpu-1g (1x H100 80GB) - Rare
- a3-highgpu-2g (2x H100 80GB) - Rare
- a3-highgpu-4g (4x H100 80GB) - Rare
- a3-highgpu-8g (8x H100 80GB) - Very Rare

**Spot Availability Patterns:**
- H100 spot availability extremely limited
- Expect frequent preemptions
- Quota often more limiting than availability
- Consider A100 as more reliable alternative

**Strategy:** H100 spot not recommended for production training. Use on-demand H100 for critical paths, spot A100 for bulk training.

From [Reddit r/googlecloud GPU Availability Discussion](https://www.reddit.com/r/googlecloud/comments/1jmorpj/gpu_availability/) (accessed 2025-01-31):
- A100s widely available at $1.25/hr spot pricing
- H100s available at $1.90/hr but limited regions
- Multiple US regions have good A100 availability

#### NVIDIA L4 (Widespread Availability)

**Regional Availability:**

**High Availability Regions:**
- Most major GCP regions
- us-central1, us-east1, us-west1
- europe-west1, europe-west4
- asia-southeast1, asia-northeast1

**Machine Types (G2 series):**
- g2-standard-4 (1x L4, 4 vCPUs)
- g2-standard-8 (1x L4, 8 vCPUs)
- g2-standard-12 (1x L4, 12 vCPUs)
- g2-standard-16 (1x L4, 16 vCPUs)
- g2-standard-24 (2x L4, 24 vCPUs)
- g2-standard-32 (1x L4, 32 vCPUs)
- g2-standard-48 (4x L4, 48 vCPUs)
- g2-standard-96 (8x L4, 96 vCPUs)

**Spot Availability Patterns:**
- Excellent availability across zones
- Suitable for inference and lightweight training
- Good for cost-sensitive workloads

**Strategy:** L4 spot instances highly reliable. Use for inference, fine-tuning, data preprocessing.

#### NVIDIA T4 (Legacy, Still Available)

**Regional Availability:**
- Widespread across most regions
- Good spot availability
- Cost-effective for older workloads

**Machine Types:**
- Attach to N1 instances (1-4 GPUs per instance)

**Strategy:** Use for cost-sensitive inference, legacy workloads, or when newer GPUs unavailable.

### TPU Spot Availability

#### TPU v4 (Production TPU)

**Regional Availability:**
- us-central2
- europe-west4

**Pod Configurations:**
- v4-8 (1 TPU pod, 8 chips)
- v4-16, v4-32, v4-64, v4-128, v4-256, v4-512
- Up to v4-4096 (512 pods)

**Spot Availability:**
- Moderate availability for small pods (v4-8, v4-16)
- Limited availability for large pods (v4-128+)
- Preemptible pricing available

**Strategy:** TPU v4 spot good for JAX/TensorFlow workloads. Start small, scale gradually.

From [GCP TPU Regions Documentation](https://docs.cloud.google.com/tpu/docs/regions-zones) (accessed 2025-01-31):
- TPU types with higher chip counts have limited availability
- Lower chip counts more readily available
- TPU quota is regional (all zones consume same quota)

#### TPU v5e (Cost-Effective TPU)

**Regional Availability:**
- us-central2
- europe-west4
- us-south1

**Preemptible Availability:**
- Good availability for small pods
- Preemptible pricing (not "spot" branding)
- Significantly cheaper than v4

**Strategy:** v5e excellent for cost-optimized training. Preemptible pricing comparable to spot discounts.

#### TPU v5p (Cutting-Edge, Limited)

**Regional Availability:**
- us-central2 (very limited)
- us-east5 (limited)

**Spot Availability:**
- Extremely limited
- No spot/preemptible pricing at launch
- Reserved for high-priority workloads

**Strategy:** Not recommended for spot strategies. Use on-demand only when necessary.

### Zone-Level Capacity Variations

**Within-Region Differences:**

Even in the same region, zones have different capacity profiles:

```
us-central1 ZONE COMPARISON
============================

Zone            | A100 Spot | H100 Spot | General Capacity
----------------|-----------|-----------|------------------
us-central1-a   | â–ˆâ–ˆâ–ˆâ–ˆ      | â–ˆâ–ˆ        | High
us-central1-b   | â–ˆâ–ˆâ–ˆâ–ˆ      | â–ˆâ–ˆ        | High
us-central1-c   | â–ˆâ–ˆâ–ˆ       | -         | Good
us-central1-f   | â–ˆâ–ˆâ–ˆ       | -         | Good
```

**Strategy:** Deploy across multiple zones within a region for resilience.

---

## Section 3: Capacity Planning Strategies

### Multi-Zone Deployment for Resilience

**Core Strategy:** Never rely on a single zone for spot capacity.

#### Implementation Pattern

```yaml
# Multi-zone spot deployment
training_job:
  regions:
    primary: us-central1
    fallback: us-east1

  zones_us_central1:
    - us-central1-a  # Priority 1
    - us-central1-b  # Priority 2
    - us-central1-c  # Priority 3

  instance_config:
    machine_type: a2-highgpu-8g
    provisioning_model: SPOT
    automatic_restart: false  # Spot VMs don't support auto-restart

  placement_policy:
    zone_selection: FLEXIBLE  # Let GCP place where capacity available
    collocation: BEST_EFFORT  # Try to colocate multi-node jobs
```

From [GCP Best Practices for Region Selection](https://docs.cloud.google.com/solutions/best-practices-compute-engine-region-selection) (accessed 2025-01-31):
- Deploy across multiple zones for fault tolerance
- Deploy across multiple regions for disaster recovery
- Consider latency, data residency, and cost implications

#### Multi-Zone Training Script

```python
# multi_zone_spot_training.py
import subprocess
import time
from google.cloud import compute_v1

class MultiZoneSpotManager:
    """Manages spot instance deployment across multiple zones"""

    def __init__(self, project_id, region, zones):
        self.project_id = project_id
        self.region = region
        self.zones = zones  # Priority-ordered list
        self.compute_client = compute_v1.InstancesClient()

    def create_spot_instance(self, zone, instance_config):
        """Attempt to create spot instance in specific zone"""
        try:
            instance = compute_v1.Instance()
            instance.name = instance_config['name']
            instance.machine_type = f"zones/{zone}/machineTypes/{instance_config['machine_type']}"

            # Spot provisioning model
            instance.scheduling = compute_v1.Scheduling()
            instance.scheduling.provisioning_model = "SPOT"
            instance.scheduling.instance_termination_action = "DELETE"

            # Configure disks, network, etc.
            # ... (full configuration)

            operation = self.compute_client.insert(
                project=self.project_id,
                zone=zone,
                instance_resource=instance
            )

            # Wait for completion
            self.wait_for_operation(operation, zone)
            return True, zone

        except Exception as e:
            print(f"Failed to create instance in {zone}: {e}")
            return False, None

    def deploy_with_fallback(self, instance_config):
        """Try each zone in priority order until success"""
        for zone in self.zones:
            print(f"Attempting deployment in {zone}...")
            success, deployed_zone = self.create_spot_instance(zone, instance_config)

            if success:
                print(f"âœ“ Successfully deployed in {deployed_zone}")
                return deployed_zone

            print(f"âœ— Failed in {zone}, trying next zone...")
            time.sleep(5)  # Brief delay before retry

        raise RuntimeError("Failed to deploy in any zone")

    def multi_zone_distributed_training(self, num_nodes, instance_config):
        """Deploy multi-node training across zones"""
        deployed_instances = []

        for i in range(num_nodes):
            node_config = instance_config.copy()
            node_config['name'] = f"trainer-node-{i}"

            # Try to deploy in priority zone, fallback if needed
            zone = self.deploy_with_fallback(node_config)
            deployed_instances.append({
                'node': i,
                'zone': zone,
                'name': node_config['name']
            })

        print(f"\nâœ“ Deployed {num_nodes} nodes across zones:")
        for instance in deployed_instances:
            print(f"  Node {instance['node']}: {instance['zone']}")

        return deployed_instances

# Usage
manager = MultiZoneSpotManager(
    project_id="my-project",
    region="us-central1",
    zones=["us-central1-a", "us-central1-b", "us-central1-c"]
)

# Deploy 4-node training job with zone fallback
nodes = manager.multi_zone_distributed_training(
    num_nodes=4,
    instance_config={
        'machine_type': 'a2-highgpu-8g',
        'disk_size_gb': 500,
        'gpu_count': 8
    }
)
```

### Fallback Region Strategies

**Multi-Region Deployment Pattern:**

```
PRIMARY REGION STRATEGY
=======================

Tier 1 (Primary):
  Region: us-central1
  Zones: us-central1-a, us-central1-b, us-central1-c
  Use Case: Primary training location

Tier 2 (Fallback):
  Region: us-east1
  Zones: us-east1-b, us-east1-c, us-east1-d
  Use Case: Failover if us-central1 exhausted

Tier 3 (Emergency):
  Region: us-west1
  Zones: us-west1-a, us-west1-b
  Use Case: Last resort, may use L4 instead of A100
```

**Implementation:**

```python
class MultiRegionCapacityPlanner:
    """Plans spot capacity across multiple regions"""

    REGIONS = [
        {
            'name': 'us-central1',
            'priority': 1,
            'zones': ['us-central1-a', 'us-central1-b', 'us-central1-c'],
            'gpu_types': ['A100', 'H100', 'L4'],
            'estimated_availability': 0.85  # 85% typical availability
        },
        {
            'name': 'us-east1',
            'priority': 2,
            'zones': ['us-east1-b', 'us-east1-c', 'us-east1-d'],
            'gpu_types': ['A100', 'L4'],
            'estimated_availability': 0.75
        },
        {
            'name': 'us-west1',
            'priority': 3,
            'zones': ['us-west1-a', 'us-west1-b'],
            'gpu_types': ['L4', 'T4'],
            'estimated_availability': 0.65
        }
    ]

    def select_optimal_region(self, gpu_requirement, fallback_allowed=True):
        """Select region based on GPU availability"""
        for region in self.REGIONS:
            if gpu_requirement in region['gpu_types']:
                print(f"Selected {region['name']} for {gpu_requirement}")
                print(f"  Estimated availability: {region['estimated_availability']*100}%")
                return region
            elif fallback_allowed:
                print(f"{region['name']}: {gpu_requirement} not available")
                continue

        raise ValueError(f"No region supports {gpu_requirement}")
```

### Capacity Reservation (Not for Spot)

**Important:** Capacity reservations do NOT apply to spot instances.

From [GCP Regions Documentation](https://docs.cloud.google.com/compute/docs/regions-zones) (accessed 2025-01-31):
- Resource quotas separate for spot vs on-demand
- Certain resources (GPUs, TPUs) may have limited availability
- Spot VMs have no availability guarantee regardless of quota

**Strategy:** Use capacity reservations for on-demand fallback, not spot primary.

### Historical Availability Analysis

**Monitoring Spot Availability:**

```bash
# Check current spot availability via gcloud
gcloud compute instances describe-available-machine-types \
  --zone=us-central1-a \
  --filter="machineType:a2-highgpu"

# Check GPU availability
gcloud compute accelerator-types list \
  --filter="zone:(us-central1-a)" \
  --format="table(name,zone,maximumCardsPerInstance)"
```

**Availability Tracking Script:**

```python
# spot_availability_tracker.py
import time
from datetime import datetime
from google.cloud import monitoring_v3

class SpotAvailabilityTracker:
    """Track spot instance availability patterns over time"""

    def __init__(self, project_id, regions_zones):
        self.project_id = project_id
        self.regions_zones = regions_zones
        self.availability_history = []

    def check_zone_availability(self, zone, machine_type):
        """Check if spot capacity available in zone"""
        try:
            # Attempt to create spot instance (dry-run or quick create/delete)
            # This is a simplified check - production would use more sophisticated methods
            result = subprocess.run(
                [
                    'gcloud', 'compute', 'instances', 'create', 'test-spot',
                    f'--zone={zone}',
                    f'--machine-type={machine_type}',
                    '--provisioning-model=SPOT',
                    '--dry-run'
                ],
                capture_output=True,
                timeout=30
            )
            available = result.returncode == 0

        except Exception:
            available = False

        return available

    def monitor_availability(self, machine_type, interval_minutes=15):
        """Continuously monitor spot availability"""
        while True:
            timestamp = datetime.now()

            for region, zones in self.regions_zones.items():
                for zone in zones:
                    available = self.check_zone_availability(zone, machine_type)

                    self.availability_history.append({
                        'timestamp': timestamp,
                        'region': region,
                        'zone': zone,
                        'machine_type': machine_type,
                        'available': available
                    })

                    print(f"{timestamp} | {zone} | {machine_type} | "
                          f"{'âœ“ Available' if available else 'âœ— Unavailable'}")

            time.sleep(interval_minutes * 60)

    def get_availability_stats(self, zone, hours=24):
        """Calculate availability percentage over time period"""
        cutoff = datetime.now() - timedelta(hours=hours)
        zone_history = [
            h for h in self.availability_history
            if h['zone'] == zone and h['timestamp'] > cutoff
        ]

        if not zone_history:
            return None

        available_count = sum(1 for h in zone_history if h['available'])
        availability_pct = (available_count / len(zone_history)) * 100

        return availability_pct

# Usage
tracker = SpotAvailabilityTracker(
    project_id="my-project",
    regions_zones={
        'us-central1': ['us-central1-a', 'us-central1-b', 'us-central1-c'],
        'us-east1': ['us-east1-b', 'us-east1-c']
    }
)

# Monitor A100 8-GPU availability
tracker.monitor_availability('a2-highgpu-8g', interval_minutes=15)
```

### Time-of-Day Patterns (Unreliable)

**General Observation:** Spot availability may vary by time of day, but patterns are NOT reliable enough for planning.

**Why Time-Based Patterns Don't Work:**
- GCP capacity driven by global demand, not local time
- ML workloads run 24/7, no clear "off-peak"
- Preemption can occur at any time regardless of hour
- Availability changes based on overall cloud usage, not clock

**Strategy:** Don't rely on time-based capacity planning. Use multi-zone deployment instead.

### Monitoring Availability with APIs

**GCP Compute API for Availability Checks:**

```python
from google.cloud import compute_v1

def check_machine_type_availability(project_id, zone, machine_type):
    """Check if specific machine type available in zone"""
    client = compute_v1.MachineTypesClient()

    try:
        # Get machine type details
        machine = client.get(
            project=project_id,
            zone=zone,
            machine_type=machine_type
        )

        # If we can fetch it, it's potentially available
        # (doesn't guarantee spot capacity though)
        return True, machine

    except Exception as e:
        return False, str(e)

def check_gpu_availability(project_id, zone):
    """List available GPU types in zone"""
    client = compute_v1.AcceleratorTypesClient()

    accelerators = client.list(project=project_id, zone=zone)

    gpu_list = []
    for accelerator in accelerators:
        gpu_list.append({
            'name': accelerator.name,
            'max_cards': accelerator.maximum_cards_per_instance
        })

    return gpu_list

# Check A100 availability
available, result = check_machine_type_availability(
    'my-project',
    'us-central1-a',
    'a2-highgpu-8g'
)

if available:
    print(f"âœ“ a2-highgpu-8g available in us-central1-a")
else:
    print(f"âœ— Not available: {result}")

# List GPUs
gpus = check_gpu_availability('my-project', 'us-central1-a')
for gpu in gpus:
    print(f"  {gpu['name']}: max {gpu['max_cards']} cards")
```

### Automated Region Switching

**Dynamic Region Selection:**

```python
class AutomatedRegionSwitcher:
    """Automatically switch regions based on availability"""

    def __init__(self, project_id, region_preferences):
        self.project_id = project_id
        self.region_preferences = region_preferences  # Ordered list
        self.current_region = None
        self.current_zone = None

    def find_available_capacity(self, machine_type, gpu_type=None):
        """Search regions in order for available capacity"""
        for region in self.region_preferences:
            for zone in region['zones']:
                # Check availability
                available = self.check_capacity(zone, machine_type, gpu_type)

                if available:
                    self.current_region = region['name']
                    self.current_zone = zone
                    print(f"âœ“ Found capacity: {zone}")
                    return zone

                print(f"âœ— No capacity: {zone}")

        # No capacity found
        return None

    def launch_with_auto_region(self, instance_config):
        """Launch instance with automatic region selection"""
        zone = self.find_available_capacity(
            instance_config['machine_type'],
            instance_config.get('gpu_type')
        )

        if not zone:
            raise RuntimeError("No spot capacity available in any region")

        # Launch in found zone
        return self.create_instance(zone, instance_config)

    def monitor_and_relocate(self, instance_name, check_interval=300):
        """Monitor instance, relocate if preempted"""
        while True:
            # Check if instance still running
            instance = self.get_instance_status(instance_name)

            if instance['status'] == 'TERMINATED':
                print(f"âš  Instance {instance_name} terminated (likely preempted)")

                # Find new capacity
                zone = self.find_available_capacity(
                    instance['machine_type']
                )

                if zone:
                    print(f"â†» Relaunching in {zone}...")
                    self.relaunch_instance(instance_name, zone)
                else:
                    print("âœ— No capacity available for relaunch")
                    break

            time.sleep(check_interval)

# Usage
switcher = AutomatedRegionSwitcher(
    project_id="my-project",
    region_preferences=[
        {
            'name': 'us-central1',
            'zones': ['us-central1-a', 'us-central1-b', 'us-central1-c']
        },
        {
            'name': 'us-east1',
            'zones': ['us-east1-b', 'us-east1-c']
        }
    ]
)

# Launch with auto-region selection
switcher.launch_with_auto_region({
    'name': 'training-job-1',
    'machine_type': 'a2-highgpu-8g',
    'gpu_type': 'nvidia-tesla-a100'
})
```

---

## Complete Capacity Planning Workflow

### Production-Ready Capacity Strategy

```python
# production_capacity_planner.py

class ProductionCapacityPlanner:
    """Complete capacity planning for production ML training"""

    def __init__(self, project_id):
        self.project_id = project_id
        self.region_config = self.load_region_config()
        self.availability_tracker = SpotAvailabilityTracker(project_id)
        self.multi_zone_manager = MultiZoneSpotManager(project_id)

    def load_region_config(self):
        """Load region configuration with priorities"""
        return {
            'primary': {
                'region': 'us-central1',
                'zones': ['us-central1-a', 'us-central1-b', 'us-central1-c'],
                'gpu_types': ['A100', 'H100', 'L4'],
                'priority': 1
            },
            'fallback': {
                'region': 'us-east1',
                'zones': ['us-east1-b', 'us-east1-c', 'us-east1-d'],
                'gpu_types': ['A100', 'L4'],
                'priority': 2
            },
            'emergency': {
                'region': 'us-west1',
                'zones': ['us-west1-a', 'us-west1-b'],
                'gpu_types': ['L4', 'T4'],
                'priority': 3
            }
        }

    def plan_training_job(self, job_config):
        """Plan optimal deployment for training job"""
        print(f"\nðŸ“‹ Planning training job: {job_config['name']}")
        print(f"   GPU requirement: {job_config['gpu_type']}")
        print(f"   Node count: {job_config['num_nodes']}")

        # Step 1: Select optimal region
        selected_region = self.select_region(job_config['gpu_type'])

        # Step 2: Check historical availability
        availability = self.check_historical_availability(
            selected_region,
            job_config['machine_type']
        )
        print(f"   Historical availability: {availability:.1f}%")

        # Step 3: Plan multi-zone deployment
        deployment_plan = self.plan_multi_zone_deployment(
            selected_region,
            job_config['num_nodes']
        )

        # Step 4: Estimate reliability
        reliability = self.estimate_reliability(deployment_plan)
        print(f"   Estimated reliability: {reliability:.1f}%")

        return deployment_plan

    def execute_deployment(self, deployment_plan):
        """Execute planned deployment with monitoring"""
        print(f"\nðŸš€ Executing deployment...")

        # Deploy instances
        instances = []
        for node in deployment_plan['nodes']:
            instance = self.multi_zone_manager.deploy_with_fallback(
                node['config']
            )
            instances.append(instance)

        # Set up monitoring
        self.setup_preemption_monitoring(instances)

        # Set up auto-recovery
        self.setup_auto_recovery(instances, deployment_plan)

        return instances

    def setup_preemption_monitoring(self, instances):
        """Monitor for preemption events"""
        # Configure Cloud Monitoring alerts
        # Alert on instance termination
        # Trigger recovery workflow
        pass

    def setup_auto_recovery(self, instances, deployment_plan):
        """Auto-recover from preemption"""
        # Configure Cloud Functions or Cloud Run
        # Automatically relaunch preempted instances
        # Resume training from latest checkpoint
        pass

# Complete workflow
planner = ProductionCapacityPlanner(project_id="my-project")

# Plan 4-node A100 training job
job_config = {
    'name': 'llm-training-job-1',
    'gpu_type': 'A100',
    'machine_type': 'a2-highgpu-8g',
    'num_nodes': 4,
    'checkpoint_frequency': '10min',
    'max_runtime': '24h'
}

# Plan deployment
deployment_plan = planner.plan_training_job(job_config)

# Execute
instances = planner.execute_deployment(deployment_plan)

print(f"\nâœ… Training job deployed across {len(instances)} instances")
for i, instance in enumerate(instances):
    print(f"   Node {i}: {instance['zone']}")
```

---

## Key Takeaways

1. **Multi-Zone is Mandatory:** Never rely on single-zone spot capacity
2. **Region Selection Matters:** us-central1, us-east1, europe-west4 have best availability
3. **GPU Scarcity:** A100 widely available, H100 extremely limited
4. **No Time Patterns:** Don't rely on time-of-day for capacity planning
5. **Automated Failover:** Implement automated region/zone switching
6. **Monitoring Essential:** Track availability patterns, preemption rates
7. **TPUs More Reliable:** TPU v4/v5e spot availability better than H100
8. **L4 Most Reliable:** L4 GPUs have best spot availability across regions

---

## Sources

**GCP Official Documentation:**
- [Spot VMs](https://docs.cloud.google.com/compute/docs/instances/spot) - Spot instance fundamentals (accessed 2025-01-31)
- [Regions and Zones](https://docs.cloud.google.com/compute/docs/regions-zones) - Regional architecture (accessed 2025-01-31)
- [GPU Regions and Zones](https://docs.cloud.google.com/compute/docs/gpus/gpu-regions-zones) - GPU availability (accessed 2025-01-31)
- [TPU Regions](https://docs.cloud.google.com/tpu/docs/regions-zones) - TPU availability (accessed 2025-01-31)
- [Best Practices for Region Selection](https://docs.cloud.google.com/solutions/best-practices-compute-engine-region-selection) - Region planning (accessed 2025-01-31)

**Industry Research:**
- [Cast.AI GPU Report 2025](https://cast.ai/reports/gpu-price-2025/) - A100/H100 availability analysis (accessed 2025-01-31)
- [Cast.AI Spot Instance Availability](https://cast.ai/blog/spot-instance-availability-demystified-aws-azure-and-gcp/) - Multi-cloud spot patterns (accessed 2025-01-31)

**Community Resources:**
- [Reddit r/googlecloud GPU Availability](https://www.reddit.com/r/googlecloud/comments/1jmorpj/gpu_availability/) - Real-world GPU availability reports (accessed 2025-01-31)

**Additional References:**
- [CloudZero GCP Availability Zones](https://www.cloudzero.com/blog/gcp-availability-zones/) - Zone architecture (accessed 2025-01-31)
- [Pump.co GCP Spot VMs Guide](https://www.pump.co/blog/spot-instances-gcp) - Spot fundamentals (accessed 2025-01-31)
