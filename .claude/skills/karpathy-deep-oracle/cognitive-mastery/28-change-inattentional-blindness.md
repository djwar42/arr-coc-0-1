# Change Blindness & Inattentional Blindness

## Overview

Change blindness and inattentional blindness reveal fundamental limitations in human visual awareness, demonstrating that we perceive far less than we subjectively experience. These phenomena challenge the intuitive notion that we maintain rich, detailed representations of our visual environment.

**Change blindness** is the failure to detect significant changes in visual scenes when attention is not directed to the changing element, even when changes are large and obvious once noticed.

**Inattentional blindness** is the failure to perceive otherwise visible stimuli when attention is focused elsewhere, even when the unattended stimulus appears directly in the visual field.

From [Change Blindness - ScienceDirect](https://www.sciencedirect.com/topics/psychology/change-blindness) (accessed 2025-11-16):
> Change blindness is defined as a phenomenon where individuals fail to notice significant changes in visual scenes when their attention is not explicitly focused on the changing element, although these changes become apparent once attention is directed to them.

## Change Blindness: Core Phenomena

### The Flicker Paradigm

The **flicker paradigm** is the primary experimental method for inducing change blindness. Two nearly-identical scenes (with one change between them) are presented in alternating sequence, separated by a brief blank screen or visual disruption.

From [Visual Experience and Guidance of Action](https://www.sciencedirect.com/science/article/pii/S1053810018300515) (Spivey & Batzloff, 2018):
> This intervening blank-screen method is called the "flicker paradigm," and has been used to show that a wide variety of scene changes can often go undetected. However, briefly replacing the scene with a blank screen is not required for change blindness to occur. A brief scattering of visual splotches (or "mudsplashes") on an image, during the change, has the same effect as the flicker paradigm.

**Key experimental findings:**
- Without disruption, instantaneous scene transitions generate perceptual flashes or movement at change locations
- A blank screen as brief as a fraction of a second eliminates this perceptual anomaly
- "Mudsplashes" (visual splotches) scattered during changes produce change blindness without occluding the change
- Reversing image polarity during transitions can induce change blindness without additional disruptions

### Types of Change Blindness

**Change blindness occurs across multiple contexts:**

1. **Saccadic changes** - Changes during eye movements (Grimes, 1996)
2. **Blink-induced changes** - Changes during eye blinks (O'Regan et al., 2000)
3. **Cuts in motion pictures** - Changes across film edits (Levin & Simons, 1997; Simons, 1996)
4. **Gradual changes** - Slow transformations that don't automatically draw attention
5. **Real-world person substitutions** - Failure to notice conversation partners being replaced by different people (Simons & Levin, 1998)

From [Visual Experience and Guidance of Action](https://www.sciencedirect.com/science/article/pii/S1053810018300515):
> Even quite dramatic changes can sometimes go unnoticed, such as the stranger you're talking to suddenly changing into a different stranger after being interrupted by two people carrying a door (Simons & Levin, 1998). Half of the participants failed to detect that change!

### Factors Affecting Change Detection

**Detection improves when:**
- Eye movements toward targets indicate attention allocation
- Observers fixate the changing object before and after change
- Saccades are in progress when changes occur (Henderson & Hollingworth, 1999)
- Hands are placed near displays, enhancing visual processing (Tseng & Bridgeman, 2011)
- Changes affect task-relevant objects vs. incidental scene elements
- Spatial proximity exists between attended and changing locations (though evidence is mixed)

From [Change Blindness chapter](https://www.sciencedirect.com/science/article/pii/B9780123738738000062) (Rensink, 2009):
> Visual attention appears to be critical for the creation (and perhaps maintenance) of internal representations with a spatiotemporal coherence that in some sense matches that of the external object(s) they describe.

## Inattentional Blindness: The Invisible Gorilla

### Classic Demonstrations

The most famous inattentional blindness study is the **Invisible Gorilla experiment** by Simons and Chabris (1999), which earned an Ig Nobel Prize.

From [Gorillas in our midst](https://pubmed.ncbi.nlm.nih.gov/10694957/) (Simons & Chabris, 1999):
> With each eye fixation, we experience a richly detailed visual world. Yet recent work on visual integration and change direction reveals that we are surprisingly unaware of the details of our environment from one view to the next: we often do not detect large changes to objects and scenes ('change blindness'). Furthermore, without attention, we may not even perceive objects ('inattentional blindness').

**Experimental paradigm:**
- Participants watch a video of people passing basketballs
- Viewers count passes made by players wearing white shirts
- A person in a gorilla suit walks through the center of the scene for several seconds
- Approximately 50% of observers fail to notice the gorilla

**Key findings from Simons & Chabris (1999):**
- Likelihood of noticing unexpected objects depends on similarity to attended objects
- Detection varies with difficulty of the primary monitoring task
- Spatial proximity of critical unattended objects to attended locations does NOT reliably affect detection
- Observers appear to attend to objects and events, not merely spatial positions

### Real-World Implications

From [What is the Bandwidth of Perceptual Experience?](https://www.sciencedirect.com/science/article/pii/S1364661316000668) (Cohen et al., 2016):
> Perhaps more commonly, automobile accidents regularly occur because drivers fail to notice items on the road (e.g., another car or a pedestrian) when their attention is directed elsewhere (e.g., their cell phone conversation).

**Practical consequences:**
- Traffic accidents from cell phone use while driving
- Medical imaging errors (radiologists missing anomalies)
- Security screening failures
- Eyewitness testimony inaccuracies
- Aviation safety incidents

## Theoretical Explanations

### Attention as Prerequisite for Awareness

From [Gorillas in our midst](https://pubmed.ncbi.nlm.nih.gov/10694957/) (Simons & Chabris, 1999):
> Taken together, these findings suggest that we perceive and remember only those objects and details that receive focused attention.

**Core theoretical claim:**
Conscious visual experience requires focused attention. Without attention directed to an object or change, that stimulus may not enter awareness despite being physically visible and potentially processed by early visual areas.

### Representational Limitations

From [Visual Experience and Guidance of Action](https://www.sciencedirect.com/science/article/pii/S1053810018300515):
> The only reason that any change blindness is surprising is if one assumes that there is an accurate internal mental representation of the visual scene stored in an observer's brain. By contrast, if one assumes that there is no internal maintenance of visual information over time at all, then one should be surprised by any change detection.

**Competing theoretical positions:**

1. **No visual memory hypothesis** - Memory for local visual objects is non-existent (O'Regan, 1992; O'Regan & Noë, 2001)
2. **Attended-object-only hypothesis** - Memory limited to currently attended object (Rensink, 2000; Wolfe, 1999)
3. **Limited-capacity hypothesis** - Memory for attended object plus 2-3 most recently attended objects (Irwin, 1992; Irwin & Andrews, 1996)
4. **Retention-with-retrieval-failure hypothesis** - Representations from previously attended objects retained robustly, but change blindness derives from retrieval and comparison failures (Hollingworth & Henderson, 2002)

### Recurrent Processing Requirement

From [Why visual attention and awareness are different](https://www.sciencedirect.com/science/article/pii/S136466130200013X) (Lamme, 2003):
> Conscious visual experience requires recurrent processing. Visual input reaches the early visual areas (V1) at ~40 ms after stimulus onset. Visual information is then rapidly fed forward to the extrastriate areas and parietal and temporal cortex (~60 ms). This feedforward sweep of information processing is unconscious. At around 100 ms, early visual areas and higher areas engage in recurrent interactions, which are necessary for conscious visual experience.

**Temporal dynamics:**
- 40 ms: Visual input reaches V1
- 60 ms: Feedforward sweep to extrastriate, parietal, temporal cortex (unconscious)
- 100 ms: Recurrent interactions between early and higher visual areas (conscious experience emerges)

### Ecological Perception Perspective

From [Visual Experience and Guidance of Action](https://www.sciencedirect.com/science/article/pii/S1053810018300515):
> Bruce later echoed that perspective when he wrote, "perception is something you do, not something that happens to you" (Bridgeman & Tseng, 2011, p. 73).

**Gibsonian ecological view:**
- Perception is active engagement with environment, not passive reception
- Visual experience is not stored in observer, but emerges from interaction
- Hands near displays enhance visual processing through action-readiness
- O'Regan & Noë (2001): "The experience you have looking at [objects] is not something that occurs in you or to you, it is something you do"

## Capacity Limitations: Working Memory & Attention

### The Richness Illusion

From [What is the Bandwidth of Perceptual Experience?](https://www.sciencedirect.com/science/article/pii/S1364661316000668) (Cohen et al., 2016):
> Even when attention is entirely focused on a single item, no one has the impression that the rest of the world fades into darkness. Instead, observers believe they have a rich perceptual experience that spans the entire field of view. This belief has been experimentally verified by the fact that naïve observers systematically overestimate the capacities of attention and working memory.

**Empirical capacity limits:**
- Visual working memory: ~3-4 items (slot models) or fluid resource distributed across items
- Visual attention: Initially estimated at 3-4 locations, more recent work suggests 7-8 locations
- Both change blindness and inattentional blindness arise from limited ability to attend to and remember multiple items simultaneously

**Models of capacity:**
1. **Fixed slots model** - Discrete number of items (3-4) can be stored
2. **Flexible resource model** - Fluid cognitive resource distributed across attended items
3. Both models converge on similar practical limits

### Attention vs. Awareness Debate

From [Attention: Change Blindness and Inattentional Blindness](https://www.sciencedirect.com/science/article/pii/B9780123738738000062) (Rensink, 2009):
> CB refers to the failure of an observer to visually experience changes that are easily seen once noticed. This can happen even if the changes are large, constantly repeat, and the observer has been informed that they will occur. A related phenomenon is IB – the failure to visually experience an object or event when attention is directed elsewhere.

**Key distinction:**
- Both phenomena demonstrate dramatic perceptual failures
- Both are highly counterintuitive subjectively and objectively
- Both challenge existing ideas about human vision
- Both occur despite changes/objects being "easily seen once noticed"

## Applications to ARR-COC-0-1 (10%)

### Relevance Realization as Change Detection

Change blindness reveals that **salience alone is insufficient for awareness** - attention allocation determines what enters conscious experience. This directly informs ARR-COC-0-1's relevance realization framework.

**Key parallels:**

1. **Attention as gating mechanism**: Just as human attention gates visual awareness, ARR-COC-0-1's relevance scorers gate which visual patches receive high LOD allocation

2. **Task-dependent allocation**: Change detection improves for task-relevant objects. Similarly, ARR-COC-0-1's Participatory knowing scorer (cross-attention with query) allocates resources based on query relevance

3. **Limited capacity**: Human vision maintains detailed representations only for attended objects (~3-4 items). ARR-COC-0-1 maintains high-detail representations only for highly relevant patches (K=200 patches, 64-400 tokens each)

4. **Dynamic reallocation**: Eye movements improve change detection when directed to changing objects. ARR-COC-0-1's dynamic token allocation shifts resources as relevance landscapes change

### Opponent Processing and Attention Trade-offs

From [Gorillas in our midst](https://pubmed.ncbi.nlm.nih.gov/10694957/):
> Interestingly, spatial proximity of the critical unattended object to attended locations does not appear to affect detection, suggesting that observers attend to objects and events, not spatial positions.

**ARR-COC-0-1 design implications:**
- **Compress ↔ Particularize**: Balance between low LOD (compressed, change-blind) and high LOD (particularized, change-sensitive)
- **Exploit ↔ Explore**: Allocate to known-relevant patches (exploit) vs. scan for unexpected changes (explore)
- **Focus ↔ Diversify**: Concentrate resources on task-relevant objects vs. maintain peripheral awareness

### Distributed Inference Trade-offs

**Influenced by Files 1, 5, 13:**

From File 1 (DeepSeek ZeRO):
- **Memory-efficient attention**: Partition attention computation across GPUs similar to how human attention partitions awareness across scene regions
- **Gradient checkpointing**: Trade computation for memory, analogous to trading attention for peripheral awareness

From File 5 (TensorRT Inference):
- **Dynamic batching**: Allocate inference capacity based on request priority, similar to attention allocation based on relevance
- **Layer fusion**: Optimize attended pathways for rapid processing

From File 13 (AMD ROCm):
- **Multi-compute unit scheduling**: Distribute attention computation across MI300X compute units
- **Memory hierarchy**: Fast HBM3 for attended objects, slower memory for peripheral representations

### Implications for Training

**Change detection as meta-learning objective:**
- Train ARR-COC-0-1 to detect "changes" in input relevance landscapes
- Use flicker paradigm analog: Present image pairs with query-relevant changes
- Measure whether model allocates attention to changing regions
- Optimize for change detection accuracy weighted by query relevance

**Inattentional blindness as failure mode:**
- Model may fail to detect unexpected but query-relevant patches if initial relevance scores are low
- Requires exploration bonus or curiosity-driven allocation
- Multi-scale processing helps: Low-resolution peripheral scan can detect unexpected salience

## Research Methods and Experimental Design

### Change Detection Paradigms

**Classic methodologies:**
1. **Flicker paradigm** - Alternating images with blank intervals
2. **Mudsplash paradigm** - Visual disruptions during changes
3. **Saccade-contingent changes** - Changes during eye movements
4. **One-shot change detection** - Single change in natural viewing
5. **Real-world interruptions** - Person substitutions, environmental changes

**Dependent measures:**
- Detection accuracy (% changes noticed)
- Detection latency (time to notice change)
- Confidence ratings
- False alarm rates
- Eye movement patterns

### Inattentional Blindness Designs

**Dual-task paradigms:**
- Primary task: Count passes, track objects, monitor displays
- Critical unattended stimulus: Gorilla, color change, unexpected object
- Post-test questions: "Did you notice anything unusual?"
- Manipulation checks: Ensure primary task engagement

**Variables affecting detection:**
- Primary task difficulty
- Similarity between attended and unattended stimuli
- Duration of unattended stimulus presentation
- Spatial proximity to attended locations
- Expectation of unexpected events

## Clinical and Applied Contexts

### Sleep-Related Attention

From [Sleep-related attentional bias in insomnia](https://www.sciencedirect.com/science/article/pii/S027273581500104X) (Harris et al., 2015):
> It was found that change-detection latencies for the sleep flicker were speeded for poor sleepers, compared to good sleepers (and the neutral flicker), revealing a sleep-related attentional bias in insomnia.

**Flicker paradigm applications:**
- Insomnia patients detect sleep-related changes faster than good sleepers
- Delayed Sleep Phase Syndrome (DSPS) patients show intermediate detection speeds
- Change-detection latency reflects object salience and observer history
- Demonstrates clinical utility of change blindness paradigms

### Traffic Safety

**Driving-related inattentional blindness:**
- Cell phone conversations reduce attention to road hazards
- Hands-free devices do not eliminate attention deficits
- Change blindness to traffic signals, pedestrians, vehicles
- Training interventions to improve hazard perception

### Medical Imaging

**Radiology and diagnostics:**
- Radiologists can miss visible anomalies when attention focused elsewhere
- Checklists and systematic scan protocols reduce inattentional blindness
- Expert performance still vulnerable to attention capture by salient but irrelevant features
- Computer-aided detection (CAD) systems complement human attention

## Relationship to Other Cognitive Phenomena

### Working Memory

From [What is the Bandwidth of Perceptual Experience?](https://www.sciencedirect.com/science/article/pii/S1364661316000668):
> Both change blindness and inattentional blindness arise because of observers' limited ability to attend to and remember more than a few items at a time.

**Integration with working memory limits:**
- Change blindness reflects failures to encode changes into working memory
- Inattentional blindness reflects failures to allocate attention for initial encoding
- Both phenomena constrained by same ~3-4 item capacity limits
- Attention and working memory are functionally integrated systems

### Visual Search and Attention

**Shared mechanisms:**
- Feature-based attention guides both search and change detection
- Top-down goals modulate both search efficiency and change blindness
- Similarity effects operate in both domains
- Capacity limits affect both multi-object tracking and change detection

### Consciousness and Awareness

From [Attention: Change Blindness and Inattentional Blindness](https://www.sciencedirect.com/science/article/pii/B9780123738738000062):
> Both phenomena involve a striking failure to report an object or event that is easily seen once noticed. As such, both are highly counterintuitive, not only in the subjective sense that observers have difficulty believing they could fail so badly at seeing but also in the objective sense that these findings challenge many existing ideas about how we see.

**Theoretical implications:**
- Attention may be necessary but not sufficient for consciousness
- Dissociations between access consciousness and phenomenal consciousness
- Implicit processing of unattended/unnoticed stimuli possible
- Debate over relationship between attention and visual awareness

## Future Directions

### Computational Modeling

**Model-based approaches:**
- Bayesian models of change detection with attention gating
- Predictive coding accounts of change blindness
- Neural network models with attention bottlenecks
- Comparison with human performance on standardized tasks

### Neural Mechanisms

**Neuroscience questions:**
- Role of recurrent processing in change detection
- Parietal and frontal contributions to attention allocation
- Early visual cortex representations of unattended changes
- Neural signatures distinguishing detected vs. missed changes

### Individual Differences

**Factors affecting susceptibility:**
- Working memory capacity correlates with change detection
- Age-related changes in attention and change blindness
- Clinical populations (ADHD, autism, schizophrenia)
- Training and expertise effects

### Ecological Validity

**Real-world extensions:**
- Change blindness in natural environments vs. laboratory
- Dynamic scenes with continuous changes
- Multi-modal change detection (visual + auditory)
- Social attention and change blindness for social cues

## Sources

**Source Documents:**
- None (web research only for this topic)

**Web Research:**

Primary Research Articles:
- [Gorillas in our midst: sustained inattentional blindness for dynamic events](https://pubmed.ncbi.nlm.nih.gov/10694957/) - Simons & Chabris, 1999 (accessed 2025-11-16) - The classic invisible gorilla experiment demonstrating inattentional blindness for complex objects in dynamic scenes

- [The Invisible Gorilla - Wikipedia](https://en.wikipedia.org/wiki/The_Invisible_Gorilla) (accessed 2025-11-16) - Overview of the famous experiment and the book by Chabris and Simons, winner of Ig Nobel Prize

Review Articles:
- [Change Blindness - ScienceDirect Topics](https://www.sciencedirect.com/topics/psychology/change-blindness) (accessed 2025-11-16) - Comprehensive overview of change blindness phenomena, theories, and applications across multiple cognitive science domains

- [Visual Experience and Guidance of Action: A Tribute to Bruce Bridgeman](https://www.sciencedirect.com/science/article/pii/S1053810018300515) - Spivey & Batzloff, 2018 (accessed 2025-11-16) - Historical context and detailed analysis of change blindness methodologies including flicker paradigm, mudsplashes, and ecological approaches

- [Why visual attention and awareness are different](https://www.sciencedirect.com/science/article/pii/S136466130200013X) - Lamme, 2003 (accessed 2025-11-16) - Neural timing of visual processing, distinguishing feedforward (unconscious) from recurrent (conscious) processing

- [What is the Bandwidth of Perceptual Experience?](https://www.sciencedirect.com/science/article/pii/S1364661316000668) - Cohen et al., 2016 (accessed 2025-11-16) - Analysis of capacity limitations in visual cognition, working memory, and attention, with implications for the richness of conscious experience

Theoretical Frameworks:
- [Attention: Change Blindness and Inattentional Blindness](https://www.sciencedirect.com/science/article/pii/B9780123738738000062) - Rensink, 2009 (accessed 2025-11-16) - Encyclopedia chapter surveying experimental and theoretical work on both phenomena and their implications for attention and awareness

Applied Research:
- [Sleep-related attentional bias in insomnia](https://www.sciencedirect.com/science/article/pii/S027273581500104X) - Harris et al., 2015 (accessed 2025-11-16) - Clinical application of flicker paradigm showing change detection differences in insomnia patients

**Additional References:**
- O'Regan, J.K., & Noë, A. (2001) - Sensorimotor account of vision and visual consciousness
- Rensink, R.A., O'Regan, J.K., & Clark, J.J. (1997) - Original flicker paradigm demonstrations
- Henderson, J.M., & Hollingworth, A. (1999) - Eye movements and change detection
- Grimes, J. (1996) - Saccade-contingent change blindness
- Hollingworth, A., & Henderson, J.M. (2002) - Retention and retrieval in visual memory
