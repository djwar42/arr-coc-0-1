---
sourceFile: "2025-10-28 https://www.youtube.com/watch?v=hfMk-kjRv4c&list=PLDbgk_jPPZaDvtbw9USUw91AV85y0xX2S&index=4&pp=iAQB"
exportedBy: "Kortex"
exportDate: "2025-10-28T19:01:52.078Z"
---

# 2025-10-28 https://www.youtube.com/watch?v=hfMk-kjRv4c&list=PLDbgk_jPPZaDvtbw9USUw91AV85y0xX2S&index=4&pp=iAQB

03985e3c-26a7-480a-a6e8-fd0202dfa997

2025-10-28 https://www.youtube.com/watch?v=hfMk-kjRv4c&list=PLDbgk_jPPZaDvtbw9USUw91AV85y0xX2S&index=4&pp=iAQB

6bb04a64-1bd1-4b26-a1fc-a4437b2d4be7

https://www.youtube.com/watch?v=hfMk-kjRv4c&list=PLDbgk_jPPZaDvtbw9USUw91AV85y0xX2S&index=4&pp=iAQB

hfMk-kjRv4c

## Sebastian Lague

Hello everyone, today I’d like to try teaching my 
computer to recognize various doodles and images.

Now there’re all sorts of techniques we 
could try using to tackle this problem,

but the approach I’m interested in 
at the moment is Neural Networks.

I first heard about these mysterious 
things about 10 years ago, and I soon

set about trying to program one to get 
these little stick creatures walking

around on their own. My code for handling the 
physics must have been a little buggy though,

because this was the most successful result 
I ever managed to achieve. Although, that’s

not counting the times where the creature fell 
over, and then somehow kept stretching its legs

out further and further, tricking the program 
into thinking it it was doing extremely well.

## For my second experiment

I decided to try something a bit easier: here we 
have a little 2-dimensional car with some sensors

that detect the distance to the edge of the road, 
and these values get fed into a neural network,

which then tells the car which way to steer. 
Of course it’s completely hopeless at first,

but if we let a bunch of them compete, and 
then take the top few that drove the furthest,

clone them a bunch of times with some random 
mutations to their networks, and then let

those compete, and so on, we eventually get a car 
that’s able to drive around happily on its own.

The last thing I tried doing, 
a couple of years ago now,

was training a network to identify handwritten 
digits, and once we’ve built our little neural

network today, that’s probably the 
first task we’ll try testing it on.

After that, we can see if the same code can be 
trained to recognize these tiny images of various

articles of clothing and fashion accessories 
instead. And finally, I’d like to try train it to

recognize doodles of 10 various things, such as 
helicopters, umbrellas, octopuses, and windmills.

Actually, we could even try one last thing after 
that, which is attempting to identify these little

colour images — again of 10 different things— 
this time from cars to cats, and birds to boats.

This is obviously quite a leap up in complexity 
though, so if it proves too baffling for our

simple network, then we’ll have to return in 
the future to upgrade it to something like a

convolutional neural network, which are supposed 
to be much better at these kinds of problems.

Anyway, to help figure out how we’re going to 
build our neural network, let's imagine a simple

example. We've discovered a peculiar new fruit, 
which is purple and spiky with orange spots,

and extremely delicious. Strangely though, *some* 
of them seem to be poisonous, and will give you a

terrible stomach ache. So let's examine a few 
of these fictitious fruit, and we can see that

their appearance varies in two main ways: the size 
of their spots, and the length of their spikes.

So we could try drawing a graph, with 
the size of the spots on one axis,

and the length of the spikes on the other. 
Then we could collect a bunch of fruit,

and plot them all on this graph based on those 
attributes. With some brave volunteer fruit

eaters, we’d label which were safe, and which 
turned out to be poisonous. Now if the result

ended up looking kind of random like this, then 
the spots and spikes probably don't have much

relationship with whether the fruit is poisonous 
or not, and we’d have to think of something else.

But if the data turned out looking more like 
this, then we're in business! We could draw a

little line here called a decision boundary, and 
say that any fruit we find that falls on this side

of the boundary is probably poisonous, and on 
the other side it’s more likely that it’s safe.

So our very first step is to create a simple 
network capable of determining exactly that.

We have two inputs in our problem: the size 
of the spots, and the length of the spikes;

and there were also two possible outcomes: 
safe, or poisonous. The way we’ll interpret

these is if the first output has the highest 
value, then we're predicting that it’s safe,

but if the second output has the highest 
value, our prediction is that it's poisonous.

Now you might be thinking two outputs is 
quite extravagant! Why not just have one,

and say a positive values means safe, 
and a negative value means poisonous.

And we could definitely do that, but in 
future problems there'll be more than

just two possible outcomes, so it's helpful 
to have a separate output for each of them.

All right, so these outputs obviously 
depends in some way on the inputs,

but we don’t know how much of an 
effect each input should have,

so let’s connect both inputs up to the first 
output, and these connections each represent

a weight, for essentially how important 
the inputs are to that particular output.

So the actual value of this first 
output will be equal to the first input,

multiplied by the weight of its 
connection, plus the second input,

multiplied by the weight of its connection. And 
it'll be the same story for the second output.

I've quickly written up some 
code to perform this calculation,

which you can see in this 
Classify function over here.

Then to visualize what's going on, there’s 
this Visualize function which gets run for

every pixel in the graph display, and it asks the 
network to predict whether a fruit at that point

would be considered safe or poisonous, 
and then colours the graph accordingly.

So let's see what this does. At the 
moment it’s very paranoid and seems

to think that everything is poisonous, but up 
in the corner here we have our network weights,

so I’ll play around with these a bit see if I 
can get that decision boundary how we want it.

Unfortunately, no matter what I do, I can only 
get the boundary to essentially rotate around

the origin of the graph here, when what we 
need is to be able to shift it vertically.

So let's go back to the code and make 
a tiny upgrade to our network by adding

in two new values called bias1 and bias2, 
and these will simply be added on to our

weighted inputs over here, allowing 
us to move those values up or down.

Okay, let's give it another shot. So I'll 
fiddle with the weights again to try get

the angle of the boundary correct, 
and then I’ll move on to the biases.

It's a bit finicky to control, but with some 
patient tweaking we should eventually be able

to hand-train out little network to correctly 
classify the fruit in our training sample here.

This was a pretty straightforward 
task though, so let's imagine that

when we collected this fruit data, it actually 
ended up looking something like this instead.

This is trickier of course because we can 
no longer separate safe from poisonous

with a straight line, so we’ll need to 
make some more upgrades to our network.

One way we could try to improve the network is 
simply by making it bigger. It doesn’t make sense

to change the number of inputs or outputs because 
those are determined by the problem we’re trying

to solve, but instead we can create a new layer 
that sits in between. These ‘in between’ layers

are known as ‘hidden’ layers, for whatever 
reason, and they can have as many nodes as

we like, and we could even have multiple hidden 
layers, but let's keep things simple for now.

So as these input values get fed forward to the 
next layer, they'll be multiplied by their weights

as we've seen before, and added up with a bias 
value, together creating a weighted input for

that node. And once that's been computed 
for all the nodes in the middle layer,

those values can then be fed forward in the same 
way to form the weighted inputs of the next layer.

Even for this extremely tiny network 
with only 12 weights and 5 biases,

it would be quite tedious to write out all the 
calculations by hand like I did over here, so

I’m actually going to throw all of this code out, 
and start working on a more sensible solution.

So I’ve begun by making a Layer script, 
which stores the weight values for all

the incoming connections, along with bias 
values for each node in the layer. And

these get set up over here based on the 
number of incoming and outgoing nodes.

Just to clarify… in the code I’m thinking of this 
layer, for example, as having 3 incoming nodes,

and 2 outgoing nodes. Then this 
layer would have 2 incoming nodes,

and 3 outgoing nodes. And finally this layer 
really just represents the values given to

our network, it doesn’t do anything, so it’s 
not going to be an actual layer in the code.

Alright, back to the Layer script, all that’s 
left to look at in here is this CalculateOutput

function, which takes in some input values, 
and computes the weighted inputs simply by

looping over each outgoing node, setting the 
corresponding weightedInput to that node’s

bias value, and then looping over all the 
incoming values, multiplying each of those

by the weight of their connection, and adding 
the result on to the current weightedInput.

For now at least, these weighted inputs are 
then returned as the output of the layer.

Next we have the actual NeuralNetwork class, 
which contains an array of these layers. So

when a network is created, it needs to be told 
how many nodes there should be in each layer,

and it uses that information 
to set them all up like so.

## Now over here is the function for 
calculating the output of the entire

network, and all this does is 
loop through all the layers,

calculating the output of each layer, and 
using that as the input to the next layer.

Once these inputs have been fed through the 
entire network, they’ve become the outputs.

Finally, the Classify function works 
essentially the same as before, it just

calculates the output values, and returns 
the index of whichever value is largest.

So I’ll create a network with three layers 
now, which’ll give us a lot more parameters

to play with, and let’s see what 
new and exciting things we can do!

Well it turns out, adding an extra 
layer doesn’t help at all. At least,

not on its own. To make this boundary bend,

we’re going to need to allow the layers 
to have a non-linear effect on the output.

So let's go back to our design, and zoom 
in on a single node. In a loose analogy

to biological neural networks, we can think 
of this node as a neuron, and the weighted

input over here as sort of stimulus. If 
the stimulus is sufficiently stimulating,

that should cause the neuron to fire, which in 
our model could mean outputting a value of 1;

whereas if the stimulus is small, the neuron 
wouldn’t fire, so we’d be outputting zero.

I’ll refer to this output as the 
'activation' value, so we just need

to write a little function that takes in the 
weighted input, and computes that activation

value. Something like this. And let’s quickly 
visualize that with a graph. So the x-axis here

shows the weighted input, and the y-axis 
shows the corresponding activation value.

Using an activation function like this should 
allow us to have more complex decision boundaries.

Before we can try it out though, we'll 
need to quickly jump into the Layer script,

and instead of outputting the 
weighted inputs over here,

let’s pass them through the activation function, 
and then output those activation values instead.

So returning to the joyful process of randomly 
tweaking sliders until something happens,

we can at last see that we’re able to 
actually make simple shapes with the

decision boundary. And of course, 
increasing the size of the network

now would allow us to make increasingly 
fancy shapes. But this is tiny network is

already sufficient to correctly classify 
this made-up data we have at the moment.

By the way, you might have noticed that 
the biases no longer simply shift the

whole boundary up or down, instead they’re 
just a way of easily shifting the value that

goes into the activation function. So thinking 
of our biological analogy, it would be like a

threshold that the stimulus needs to exceed 
in order for a particular neuron to fire.

Now one thing I don’t like about our current 
setup, is how abruptly and dramatically the

output can change in response to just 
a tiny tweak to some of these sliders.

So let’s go back to our choice of activation 
function, and maybe replace it with something

like this instead, which simply smooths things 
out. This is called a sigmoid function by the way,

and it’s just one of many different functions that 
people have experimented with for neural networks.

Here’s a few others, just as a matter of interest.

Anyway, let’s go with this one for now, and see 
how that affects things. So I’ll mess around with

these sliders once again, and we’re now able to 
make nice smooth boundaries. And more importantly,

making small changes to any of the sliders will no 
longer result in a drastic change to the output.

Anyway, as fun as it is trying 
endlessly to train this network by hand,

the goal of course is for the computer to 
do it all by itself. And for that to work,

it’s going to need a way to 
measure how well it's doing.

One approach would be to simply count the number 
of known data points that are being classified

correctly, but the trouble with that approach is 
that a lot of the time, a small adjustment to one

of the sliders won’t actually change that number, 
making it impossible for the computer to know if

the adjustment was beneficial or not. So we should 
try find a more precise way to measure progress.

Let’s think about the outputs of our 
network again, which are now being

squished to somewhere between 0 and 
1 by our sigmoid activation function.

So if we give the network the inputs of a fruit 
that's safe to eat, we’d hope to see a 1 at the

first output, and a zero at the second output, 
representing total confidence that it's safe.

And for a poisonous fruit, that
should be the other way around.

So since we know what the outputs should be for 
our training data, I’ve added a little function

to the Layer script called the NodeCost, which 
takes in the output activation of a single node,

along with the value we want it to be. All it does 
then is calculate the difference between the two,

and square the result, just to make it 
positive, and I guess to emphasize large

differences as being much more urgent 
to correct than small differences.

Then in the neural network script, I’ve 
added a function simply called Cost,

which takes in a single data point, such as 
one of our fruit, and runs its inputs through

the network to get the output values. Using 
those, it then loops through all the nodes in

the output layer and just adds up each of their 
individual cost values, to get an overall cost,

or measure of how bad the network 
is doing, for the given data point.

We’re most interested though in how the network 
is doing across all our data points , so here’s

another version of the cost function which 
takes in multiple datapoints this time,

and just adds up each of their 
costs, and returns the average.

So you can see that value at the bottom of the 
screen, and the goal of the network is now simply

to find values for its 17 weights and biases 
here, which result in the smallest average cost.

For the tiny network we have here, we could 
probably get away with a brute-force trial

and error approach, but our networks are going to 
get a lot bigger as we tackle trickier problems,

so we should definitely try 
to find a better solution.

Let’s simplify things by thinking first about this 
little example function, where similar to the task

of finding the weights and biases that minimize 
the cost function, we want the computer to find

the input value that results in the smallest 
output. Or at least some reasonable alternative.

And of course we’d like it to do 
this in as few steps as possible,

not just calling the function millions 
of times until it finds a good answer.

Now our solution is going to rely on 
calculating the slope of the function,

so let’s try writing some code to visualize 
it. We can approximate the slope very easily

by first defining some tiny value, which I’ll 
just call ‘h’, and then calculating how the

output of the function changes in response 
to this tiny positive nudge to the input.

The steepness of the slope will just be this 
change in the output divided by the change to

the input that caused it. So as I said, this is 
just an approximation because we’re technically

calculating the slope between two points on the 
graph, but the smaller we make h, the closer our

approximation will be to what the true slope 
would be precisely at the given input value.

Anyway, we can then visualize the 
slope with a bit of code like this.

Let’s see how that looks! So the slope 
value is pretty intuitive… we can see for

example that it’s negative over here because the 
function is decreasing as the input increases,

but it’s getting closer to zero as things 
level out, and once the function starts

increasing faster and faster, we can see the 
slope value increases as well to reflect that.

Now for a function like this one, we could 
actually do some maths to directly calculate

the points where the slope is zero, which would be 
super efficient and wonderful. But unfortunately,

the maths just isn’t viable when it 
comes to our actual neural network.

Instead, we’re going to be relying on a technique 
called Gradient Descent, and the idea here is that

we’ll pick a random starting value, and then 
just slide down the slope into the valley.

Here’s some code for doing that, which just 
initializes the input to a random value,

and then in this Learn function, it approximates 
the slope like we did a moment ago, and then

simply subtracts the slope value from the 
input value. And this learnRate parameter

here just allows us some control over how 
much the input changes with each iteration.

Let’s try it out. So I’ll give us a random 
starting value, and then I’ll just go

press this “learn” button a bunch of times to 
repeatedly run the gradient descent algorithm,

and we can see it’s very slowly 
making it’s way down the slope.

Let me restart this, and try again 
with a much higher learn rate.

But now it’s clearly trying to learn too 
quickly, because it’s just bouncing around

all over the place and not making 
any kind of consistent progress.

So we need to try strike some sort of balance 
with the learn rate, and if we manage to find a

good value for our specific problem, we can 
see it’s able to learn pretty efficiently.

Of course there’s no guarantee that 
we’ll fall into this optimal solution,

which is called the global minimum; 
we could very easily fall into a local

minimum like over here, but this process 
tends to give good results in practice,

and there’re all sorts of things we could 
experiment with in the future to try improve it.

So to get a better picture of how this will 
apply to our actual network, let’s pretend

that the network has just two weights, 
and these’ll start out with random values,

so let’s imagine them over here for example. Now 
if we want to know how good these weights are,

we could run all our data through the 
network to calculate the average cost,

and let’s represent that as a 
height in the 3rd dimension.

## We can then imagine the average 
cost that would result from any

configuration of weights as a 
kind of landscape like this.

In the previous example we approximated the 
slope by looking at how a tiny change to

the input variable affected the output of the 
function. And we could do the same thing here:

we’d look at how a tiny change to 
the first weight affects the cost,

as well as how a tiny change to the second 
weight affects the cost. And these two together

tell us the slope, or gradient rather, of the 
cost function, with respect to the weights.

So if we subtract the current gradient from 
the weights, again using the learnRate to

control things a bit, that’ll cause the 
weights to move downhill. And so with

each iteration of gradient descent, we 
can imagine our weights rolling further

down the slopes of the cost function and 
finally settling into one of the valleys.

Now obviously in our actual networks we’ll have 
loads of weights and biases affecting the cost,

so this is all happening in more 
dimensions than we can hope to imagine,

but the idea remains exactly the same.

Alright, I’m going to go ahead 
and implement all of this stuff

we’ve been talking about, and I’ll see you then!

So, over in the layer script, I’ve added these two

arrays for holding the cost gradients 
with respect to the weights and biases.

Then we have this ApplyGradients function, which 
takes in the learnRate, and it just loops over

all the weights and biases, and subtracts the 
corresponding value from the gradient like so.

I’ve also added a function for 
giving random starting values

to all of the weights, which looks like this.

Now in the NeuralNetwork script, we have this 
new Learn function, which takes in all our

training data, and it starts off by using 
that to calculate the current cost value.

Then for each weight in the network 
it makes a tiny nudge to that weight,

to measure how much that causes the cost 
to change. And it resets the weight after

doing that, just to not throw off the 
calculations for the rest of the weights.

Then it divides the change in the cost by the 
change that caused it, telling us essentially

how sensitive the cost is to the current weight; 
and it stores that in the gradient array.

This here is just the same process for 
the biases, and at the end of all this,

the gradients are applied on all of the layers.

So, as long as the learn rate isn’t too high,

this process should cause the overall cost of 
the network to decrease each time we run it.

So let’s return to our potentially poisonous 
fruit, to see if it actually works!

It has quickly found this linear boundary, 
which does an okay job of separating safe from

poisonous. And the cost is still going down, 
even though not much seems to be happening,

so let’s give it a little bit 
longer to contemplate matters…

And at last, it’s managed to 
perfectly classify the training data.

So our neural network is learning, 
which is exciting! The problem we

have now though is that it’s excruciatingly 
slow. This is mainly because we’re having

to run the cost function for every 
single weight and bias parameter,

and remember the cost function needs to feed 
all of the data it’s given through the network.

So one thing we could try is simply to give 
it less data. When we give it all of the data,

we can see the cost goes down nice and steadily 
as it learns, but if we had hundreds of thousands

of training samples, it would take a long time 
just to complete a single learning iteration.

Instead, if we give it just a tiny 
portion of the data each time —

we can complete learning iterations much faster. 
This does make the learning process noisy,

because we can imagine our cost landscape will 
look a bit different for each batch, so they won’t

all agree exactly on which way downhill is. But it 
does speed things up immesnsely, and the noisiness

can apparently even be beneficial in a number 
of ways, for example in helping to escape the

dreaded saddle point, which are regions such as 
this, where learning can slow down dramatically.

So this mini-batch technique is big 
improvement, but by itself it’s not enough.

If we want to scale our network up to, say, tens 
of thousands of weights, which is actually still

very tiny, then that would mean running each 
datapoint through the network tens of thousands

of times as well, and so our network’s going 
to take forever to learn anything interesting.

Happily for us, there is an another 
way to calculate these gradients,

where for each iteration, we’ll only have to 
run our datapoints through the network once.

And all it’s going to cost 
us…. is a bit of calculus.

In case you haven’t studied calculus, or just need

a refresher, I’d like to quickly go over 
the essential ideas we’ll be using today.

So as an example, let’s consider the function 
f(x) = x^2 -3x + 4. Here’s our code from earlier

for approximating and drawing the slope of a 
function, and we just want to figure out a more

efficient way to calculate the slope, where we 
don’t need to call the function multiple times.

So let’s consider this line first, which I’ll 
write it out here in more maths-y notation.

And let’s just see where this takes us if try 
patiently working our way through the calculation.

We can write out this f(x+h) in full, 
by just looking at our equation up here,

and wherever there’s an x, 
replacing that with x+h, like so.

And then from that we want to subtract f(x), 
so let’s write that out in full as well.

Now if we want to simplify this, we’ll 
first need to expand it all. So (x+h)^2

comes out as x^2 + 2xh + h^2, then 
we subtract 3x and 3h, we add 4,

and finally subtract the rest of this stuff. 
And now we can see that this x^2 and this

negative x^2 will gobble each other up; as 
will these two terms, and these two terms.

Once the dust settles, we’ve managed to 
simplify things quite a lot, and we can see

that h is a common factor in all these terms, 
so we could even neaten things up a little.

That’s as far as we can really take it 
though, so referring back to our code,

we then calculate the slope by dividing this 
change in the output of the function by the

tiny change to the input that caused 
it. So let’s write that out over here.

Right away we can see that these 
two h’s will cancel each other out,

and we’re left with just 2x + h - 3. Here’s 
where things get a little weird though. We

know that the closer h is to zero, the more 
accurate our approximation of the slope will

be. We also know it can’t actually *be* zero 
because then not only would the change in

the output just be zero, but we’d also 
be trying to divide everything by zero.

Nevertheless, if our answer over here gets 
more accurate the closer that h is to zero,

it makes sense intuitively that 
we should just remove h entirely.

But we don’t want to be put in maths jail, so 
let’s be a bit careful about this. First of all,

we should switch to a proper calculus notation, 
which looks like this. So the notation up here

represents an approximation, whereas this is 
going to be our exact answer. We can then add

this bit of mathematical legalese, which just 
says that as h gets closer and closer to zero,

this thing we calculated: 2x + h - 3, is going 
to get closer and closer to being just 2x - 3.

What we’ve calculated here is called the 
derivative of f with respect to x, and to

see what it means let’s go back to the graph of 
our function, and draw in its derivative as well.

Now we can see here that 
where the derivative is zero,

corresponds to where our function has zero 
slope. And where the derivative is negative,

that’s where the function is sloping 
downwards, and so on. So the derivative

is this super helpful thing that tells us the 
exact slope of our function at any input value.

Let’s quickly go into our code and create a 
little function which returns the derivative

we just figured out, and then we can replace 
all this stuff here with a single call to that

derivative function like so. Then we can try 
drawing the slope again, and it works perfectly.

So we’ve managed to make the slope calculation 
more accurate and more efficient, with the only

downside being that we have to actually figure out 
the derivative of whatever function we’re using.

Just as another quick example, here’s 
that function we used earlier when we

were thinking about gradient descent, and here 
is its derivative. And we can see again how

the derivative tells us exactly what the slope 
will be at any input value. Or put another way,

how sensitive the output of the 
function is to a change in the input.

Alright, so to figure out how all of this is 
going to actually help us, let’s consider a

ridiculously simplified network that has just 
three nodes, connected by two weights like this.

And let’s write out quickly how this works. 
So the input node receives some input value,

let’s call that “activation zero”, and we then 
calculate the weighted input, z1 for short,

which is just the input multiplied 
by the weight, plus some bias value.

Next we calculate activation 1, simply by passing 
the weighted input into our activation function.

We then do the same thing to 
calculate z2 and finally a2.

We can now evaluate the network by calculating 
the cost —so we just use the cost function,

and pass in the output activation value,

along with the expected output for the current 
training sample, or just ‘y’ for short.

Now if we think back to this horrifyingly 
inefficient gradient descent code that I wrote,

remember what we’re trying to speed 
up is this calculation here of how

sensitive the cost is to a change in 
any particular weight or bias parameter.

So let’s say we want to calculate 
that value for weight number 2 over

here. Instead of approximating it, we’ve 
seen recently that we can actually get

a more efficient answer by calculating the 
derivative. And I’ll write this with these

fancy curly d’s instead, since we’re dealing 
with functions with multiple variables now.

Anyway, this might look a bit confusing to 
calculate, because we’re trying to figure out

how w2 affects the cost, but it isn’t one of 
the cost function’s inputs. To figure it out,

there’s one final calculus concept for 
us to contemplate today: the chain rule!

The chain rule tells us to simply look at 
how w2 affects z2 — which we can write out

like this — and then look at how z2 affects 
a2 — which I’ll write over here as well — and

finally look at how a2 affects the cost — 
which, once again, I’ll write out over here.

All we need to do now, according to the rule, 
is multiply these partial derivatives together,

and it will give us the result we’re looking for.

We can even kind of see that this is 
true, because if we think about how

fractions cancel out when you multiply 
them, this gives us the correct result.

So, our task now is figuring out what each 
of these partial derivatives actually is,

and let’s start with this one on the end.

Here’s our code again for calculating the cost 
of a single node, and we need to figure out the

partial derivative of this with respect to the 
output activation value. There are shortcuts for

doing this sort of thing thankfully, but I’d 
just like to quickly show how the approach we

used earlier still works the same way for 
a multi-variable function like this one.

So over here we’re looking at how the cost 
changes in response to a tiny change to

this output activation value, and we’re 
then dividing by the size of that change.

Like before, let’s write this out in full, and 
expand everything, which is pretty tedious, but we

then get to cancel a bunch of stuff out, which is 
always satisfying. And here’s what we end up with.

I’ll tidy that up, and we can see once again, we 
end up being able to cancel out this division by

h, which is crucial to the final step of then 
being able to say that as h approaches zero,

this is going to approach simply 2 times the 
output activation minus the expected output.

So there’s our answer, and in code, 
that would just look like this.

Okay so we’ve figured that one out. Next let’s

look at how the activation changes 
in response to to the weighted input.

So here’s that sigmoid activation function we’re 
currently using, and calculating it’s derivative

is quite a bit more involved than the others, 
so I’m just going to skip right to the answer,

which turns out to be simply the activation value 
multiplied by one minus the activation value.

Let’s quickly graph it at least, just for 
interest’s sake, and here’s what it looks like.

Alright, for this last one we want to know how the 
weighted input changes in response to the weight.

This one’s very easy, because if 
we just look at our equation here,

we can see that the amount of effect that a change 
to the weight will have on the weighted input,

depends entirely on the input — which 
is this ‘a’ value here. For example,

if ‘a’ is zero, then changing the weight 
would have zero effect, whereas if ‘a’

is 10 then changing the weight would have a 10 
to 1 effect, and so on. So, that’s our answer.

## We now know how the cost is affected by the second

weight — we just need to figure out 
the same thing for the first weight.

So here’s the partial derivative we want 
to calculate, and if we just look at how

weight 1 ends up affecting the cost, we can 
again use the chain rule to figure this out.

Taking a closer look, we can see that 
these two partial derivatives on the

end are the exact same as these 
two, so we know those already.

Then this partial derivative here is 
essentially the same thing as up here,

Then over here, this is the same thing as this,

just taking place in a different layer, 
so we already know how to calculate it,

and it’s the same story with this one being the 
same thing as this, just in a different layer.

So all we need to worry about then is how the 
weighted input changes in response to the input,

but again if we just look at this equation here,

we can see that the amount of effect that 
a change to the input will have on the

weighted input is determined entirely by the 
value of the weight. So there’s our answer.

And we now know how the cost is affected 
by both of the weights in our tiny network.

I’m going to tidy these notes up a bit, because 
it’s time for our little network to grow up.

This does mean that our notes here don’t make 
total sense anymore, but they do translate

fairly intuitively I think, so they’re 
going to guide us as we work through this.

Let’s begin with this calculation over here, 
where we’re taking the partial derivative of

the cost with respect to the activation of our 
output node, and multiplying it by the derivative

of the activation with respect to the weighted 
input. Of course we now have two output nodes,

and that just means we’ll do the same calculation 
again, but using the activation of this other

output node and its weighted input instead. 
So we end up calculating two separate values,

which I’m just going to call our “node 
values” because I’m bad at naming things.

So over in the neural network script, I’ve 
started working on this little function,

which takes in a single data point 
and runs it through the network. And

I modified the layer code slightly so that 
when that happens, each layer stores all

the information we’re going to need, like 
the weighted inputs and so on. After that,

it asks the output layer to calculate the node 
values, which it does like we just talked about.

Alright, so we’re now ready to figure out how each 
weight in the final layer is affecting the cost.

So that means we’ll actually be calculating 
six different values in this example,

one for the weight of each 
of our connections here.

To do this, we need to multiply our nodeValues by 
this partial derivative here, which we figured out

earlier was just the activations from the previous 
layer. How that’ll work for this connection for

example, is we’ll take the activation from the 
previous layer that’s going to be input along

this connection, and multiply it by the node value 
that it connects to on the other end. And we’ll do

that for all of them. So just as another example, 
for this connection, we’d be taking the activation

coming out of this node, and multiplying 
it by this node value on the other end.

So over in the Layer script I’ve made this 
UpdateGradients function that takes in the

nodeValues, and then for each connection it 
calculates the partial derivative of the cost

with respect to the weight of that connection, 
and then uses that to update the weight gradient.

While we’re here, we should actually also be 
updating the bias gradient. To figure that out,

let’s quickly tweak our maths here to be with 
respect to the bias instead, and we can see we

just need to multiply the node values by whatever 
the partial derivative of the weighted input with

respect to the bias is. So let’s once again have 
a look at this equation, and here we can see here

that there’s nothing affecting the bias value, 
which means that however much the bias changes,

the weighted input will change by the same 
amount. So that partial derivative is just one.

I’ll go ahead and add that to the code quickly.

Then back in the neural network 
script, we’ll of course tell the

output layer to update its weight and 
bias gradients using our new function.

Okay, we can move on to our second equation 
here, and let’s focus on calculating this new

set of node values for our hidden layer. 
As we noticed before, this uses the old

node values in it’s calculation, so we first 
need to take those, and multiply them by this

partial derivative here, which we figured out 
earlier is the weights between the two layers.

So how this works is that the first of the new 
node values here will be equal to the weight of

this connection multiplied by the old node value 
it connects to, plus the weight of this connection

multiplied by the old node value that it 
connects to. And then, as you can probably guess,

the second new node value will be equal to this 
weight multiplied by this old node value, plus

this weight multiplied by this old node value, 
and same thing for our third new node value.

But the calculation for those new 
node values is not quite done yet,

we still need to do this bit — and so each 
of those new values will just be multiplied

by the derivative of the activation function 
with respect to the incoming weighted input.

So here’s our final addition to the layer script 
— this function takes in the old node values,

and uses them to calculate the new set 
of node values like we just talked about.

Then let’s head back to the neural network script 
to finish things up over there as well. So we can

create our new node values here, and then just use 
those to update the gradients of the hidden layer.

And at long last, we’ve now completely 
implemented our two equations!

Of course this implementation only works 
if we have just a single hidden layer,

but we can very easily modify it with a little 
loop, so that it can handle any number of layers.

By the way, this approach of starting 
with the output layer and going backwards

through the network, so that we can keep 
reusing these nodeValue calculations,

is known as the backpropagation 
algorithm. And as we can see,

it’s only running each datapoint through 
the network once — or I guess we could

call it twice since it does also have to go 
backwards through the network as well — but

that’s a huge improvement over having to do it 
for every weight and bias parameter like before.

Anyway, now that we’re able to update 
the gradients for a single data point,

I’ve made a new Learn function to replace 
the old slow one, and this takes in all the

data points in the current training batch, 
and adds up the gradients for each of them.

After that, it just performs our gradient descent 
step by telling all the layers to apply their

gradients — and remember, they multiply the 
gradient by the learn rate when doing that,

so we if just divide the learn rate 
by the size of the training batch,

that’ll average out all the 
gradients that we added together.

With that, our new learning code is 
complete, so let’s go test it on some fruit!

And it seems to be working. Of course there’s 
many things we could still to do improve it,

for example one low-hanging fruit 
would be making it process all the

datapoints in parallel, which I might 
actually quickly do behind the scenes.

Okay, let’s move on from the fruit at last,

and challenge our network to this 
classic handwritten digits dataset.

We have 70,000 images on our hands here, 
all labelled with the correct answer,

and each of these images is 
a miniscule 28x28 pixels,

so that’s 784 values ranging from 0, 
meaning black, to 1, meaning white.

Now I’ve set up a simple interface 
for creating our neural network here,

so I’ll make one with 784 inputs 
to take in all those pixel values,

and 10 outputs for telling us which of 
the 10 digits it thinks it’s looking at.

Let’s take a moment quickly to wrap our heads 
around this. So our fruit data had just two input

values, meaning we could draw each datapoint 
in 2D space. For the digits though, we now

have a 784-dimensional input space, which is a 
bit trickier to imagine. So let’s just pretend

its in 3 dimensions instead, with each axis 
representing the brightness of a single pixel.

Then perhaps images of a zero would tend to 
have values for those 3 pixels somewhere in

this region, whereas for a one maybe 
they’d more in this region over here,

and so on. I’m completely making this up of 
course, but hopefully the idea makes sense that

we can think of all the images as points somewhere 
in 784-dimensional space, and our network just

needs figure out which regions of the space each 
digit tends to hang out in. Just like it figured

out which regions of 2 dimensional space the 
safe and poisonous fruit tended to inhabit.

Okay, lets get back to setting up our network, 
and I’ll try giving this a learn rate of 1,

and a minibatch size of maybe 100, 
and That means it’ll take us 700

batches to go through all the data we 
have, which is known as one ‘epoch’.

We don’t actually want to let the 
network train on all the data though,

instead we’ll set some of it aside so that 
we can test how the network performs on data

that it hasn’t seen during it’s training, 
since that’s what we really care about.

After training for a few seconds, it seems 
to have plateaued at around 90% accuracy,

so let’s try expanding the network with a 
hidden layer, I’ll give it 100 nodes maybe,

and let’s see if it can put all 
those extra connections to good use.

It is taking a lot longer 
now to crunch the numbers,

so I’ll fast-forward through 
the training, but in the end,

we’ve managed to get around 95% accuracy, 
which is not great, but not terrible either.

To try improve it a bit, I’ve been doing some 
research, and implementing a few small things,

like some different cost and activation functions,

and also adding momentum to the gradient descent 
algorithm, which allows the weights and biases to

essentially accelerate as they slide down those 
high-dimensional slopes of the cost function.

Hopefully all of this is going to help a little,

so I’ll set it up quickly, 
and let’s see how it goes!

Well, that wasn’t a resounding success, 
but before I go hunting for bugs, let’s

just try turning the learn rate down, 
because that could also be the issue.

Okay, that’s looking much healthier! We’re 
getting over 97% of the test images correct,

which I’m pretty happy with for now. So let’s 
take a closer look at some of these images,

and up here by the way, we can see what 
the network thinks it’s looking at.

So I’ll flip though a few of these, and we 
can see it’s getting them all right so far.

I’m more more interesting in seeing 
which one’s its getting wrong though,

so I might need to add a way to find them.

Okay, I’ve added a little button here, so 
let’s try pressing it. Here’s a mistake,

it thinks this is an eight, but actually it’s a 
zero, although I can see where it’s coming from.

Then we have a 4, and I think we can 
forgive it for thinking it’s a 9.

After that — we have a 3, which it thinks is a 7,

and I can… half-sympathize; 
it’s maybe a bit unclear.

Alright, let’s look at one 
more, this time we have a 7,

which it thinks is a 2 for some reason. So some 
of it’s mistakes are kind of understandable,

but it’s also clearly making 
some very blatant errors.

We could probably get a better idea of 
it’s shortcomings if we were able to

draw our own digits, so I’ve been working 
on a super simple little drawing program

over here. I’ll hook that up to the 
neural network, and let’s try it out!

Starting off, it thinks this blank canvas is a 5,

with a confidence of 53%, and we can see the 
rankings of all the other digits below that.

So, let me start by drawing a one, 
and its managed to get that correct,

so I’ll try changing it a little bit, and all 
of a sudden it’s saying that it’s actually a 3.

That’s a bit concerning…. Well, let me try 
drawing maybe a 6; no, it thinks that’s a 5. Okay,

how about an 8? Looks like a 3, apparently. 
Well that’s not good. So it was doing

really well — 97.6% accuracy on images from the 
data set that it hadn’t seen during training — but

when I try drawing my own digits, it’s 
like it’s never seen a number before.

I think what’s going on is that all the digits 
in the dataset have been sized and centred in

a specific way, and I guess the network 
has come to rely on that being the case.

So we could obviously try processing 
our own images in the same way,

but I’m actually more interested in 
trying sort of the opposite approach.

So I’ve written some code that can 
rotate — woah that was more sensitive

than I was expecting — uhh it can 
rotate the digits in the dataset,

as well as scale them, move 
them around, and add some noise.

These settings can be applied randomly, and 
I’ll tell it to do that for all the images,

and then we can train a new 
network on that modified data.

Let’s increase the size of 
the network first though,

since that’s presumably made 
things a bit more complicated.

And it’s definitely struggling a lot more now — we 
can see it’s just scraping past 90% test accuracy.

It is over 99% accuracy on the training data 
though, which means that it’s probably learning

lots of overly specific patterns, 
essentially memorizing the answers.

So I’ve been experimenting with various 
techniques for reducing this, and what

I’m trying at the moment is simply adding some 
random noise to all of the network’s inputs,

with the hope that if it can’t rely on specific 
patterns in the images remaining exactly the same,

it will end up learning more 
general patterns instead.

From the results, we can see that it’s… 
somewhat worked. The test accuracy is up about

1 and half percent, which might not be wildly 
exciting, but it’s nothing to sneeze at either.

So, let’s go see if this new network can 
decipher my own hand-written digits a bit better.

So zero one and… two, all correct so far, so 
it’s already looking a lot more encouraging

than last time. 5 is correct as well, and 6, and 
7, and 8 — this is exciting commentary I know,

and there’s all ten digits correct 
on this first run through at least.

I’ll give it another try to make sure we didn’t 
just get completely lucky the first time,

and it has managed to get 
all of them correct again.

I’ll keep testing it for a while 
though and let you know how it goes.

I’m giving it another go to make sure we didn’t 
just get lucky the first time, but it has got

them all correct again. I’ll keep testing 
it for a while and let you know how it goes.

Okay, so it definitely does have some big 
weaknesses. For example, if I draw a one as

just a straight line, it’s very happy. But 
if I add a little stroke at the top here,

it can quite quickly starting thinking it’s a 
seven instead. We can steer the network back on

course by adding a little line to the base here 
— now it thinks it’s a one again — but if that

line extends just a tiny bit too far, the network 
will suddenly think that it’s looking at a two.

It seems to be a bit more reliable with 
other digits, like eights for example,

but even there, it doesn’t take 
too many attempts to run into a

case that bamboozles the network. Here 
it thinks it’s a nine for some reason.

Despite its flaws though, I’m happy for now 
that it at least seems to work most of the time.

Just for fun, let’s quickly try training 
our network on this fashion dataset,

which was created to be a more challenging 
drop-in replacement for the digits.

So after a few minutes of training, it’s reached 
around 89% test accuracy, which is not amazing,

but it is apparently better than human performance 
at 83 percent, which I thought was interesting.

Anyway, let’s take a brief look at some of these, 
so here’s a shirt — excuse me a t-shirt, which

it’s getting correct. Then here’s a shirt and a 
pullover, also both correct. Let’s see how long

it can keep this streak going. So we then have a 
sneaker, a dress, and another dress, then a coat…

and finally it’s been caught out by 
what it thought was another coat,

but is actually a pullover.
Okay, I thought was interesting to

try quickly, but let’s move on to our goal from 
the beginning of recognizing various doodles.

So I’ve downloaded a dataset of doodles 
drawn by people around the world,

which comes from the very 
cool “quick, draw!” project.

To keep things simple for us today, I’ve picked 
just 10 categories from the 345 that exist in

total. So we have helicopters and house 
plants, cats, cruise ships, and windmills;

along with popsicles, tractors and umbrellas, 
and our last two here — bicycles and octopuses.

So I’ve increased the size of the network yet 
again, and also added some extra hidden layers,

not for any deep reason, I’ve just been mess 
around with different settings out of curiosity.

I’ll leave this to train for a few minutes, 
and by the way, I did make the same random

transformations to the doodles as we did with 
the digits, since that seemed to be very helpful.

Alright, we’ve ended up with 
about 87% accuracy here,

but for the true test, let’s see if it 
can recognize some doodles of our own.

I’ll begin with a popsicle. 100% 
popsicle it says, very nice!

I wonder if I could give this some 
squiggly legs and turn it into an octopus.

Alright, it’s very confident 
about this being an octopus now,

with just a sliver of doubt that 
it may, in fact, be a tractor.

Let’s try something else.

So at the moment it thinks I’m drawing 
either another popsicle, or an umbrella,

although now it’s just realized that 
I’m actually trying to draw a windmill.

I see that houseplant is its second prediction, so 
let’s try planting the windmill in a little pot,

and it is saying that it’s a houseplant now, 
although it’s definitely a bit suspicious..

Anyway, I’m just going to play around with 
this for a little while, and see how it goes.

So overall I’m actually quite happy with how it’s 
working, although like with the digits earlier,

it does still make some very obvious mistakes.

I’ve printed out here it’s accuracy 
on the individual categories,

and it looks like popsicles,

umbrellas and bicycles are it’s specialty, whereas 
tractors are what really baffles it the most.

For me though, it seemed to struggle the most 
with helicopters. Here you can see its in a lot of

doubt over whether this is a tractor, a helicopter 
or a cruise ship. And in cases like this it seems

to be very sensitive to noise, for example if 
I add a random little line here, now it’s an

umbrella — out of the blue — now its back to 
being a tractor, and now its a cruise ship.

But if we can really convince the network that 
this is a helicopter, and it seems like just

emphasizing the rotor here usually does the 
trick, then it’s not nearly as indecisive.

So clearly it’s a long way from perfect,

but overall it does actually work reasonably 
well I think, so I’m happy with it for now.

To end things off today, let’s give 
our network by far it’s greatest

challenge yet… which is not supposed 
to look like this, what is going on.

Okay I forgot that these images are a whopping 
32 pixels wide now, let’s try that again.

So these images are a bit bigger 
and in colour, which means we have

3072 inputs now instead of just 784, and 
let’s take a closer look at some of them.

Right away we can see that this is 
going to be trickier for the network,

because the object or creature it needs 
to recognize hasn’t been nicely cut out

for it or anything, there’s the whole 
environment around it to confuse matters.

And we can also see how much variety there 
is, even just among pictures of birds for

example. We’ve got little birds on 
branches, big birds jogging around,

birds swimming, birds flying, birds starting 
straight into your soul, you name it.

So with all this complexity in mind, let’s see 
how our simple network fares in its training.

Not terribly well is unfortunately the answer — it 
ended up with an accuracy of about 53%, but let’s

take a look anyway. To begin with we have a deer 
which it thinks is in airplane, and a dog which it

thinks is a horse, so not off to a good start. It 
has recognized this bird though, as well as this

little dog in a box, but then this aeroplane 
it’s unfortunately misidentified as a ship.

Let’s see what’s next, so this time 
ship was correct, and then we have an

automobile and a truck — both correct 
— but that is certainly not a horse!

So as expected, it’s getting about half of them 
correct, which is of course a lot better than

random, but still a pretty underwhelming result. 
I’m sure we could coax a bit more accuracy out

of our simple network with some tweaks here 
and there, but if we want it to really be

able to take on this challenge, it’s going 
to require some more significant upgrades.

Sometime in the future, I hope to return 
to this project and do exactly that.

That’s all for now though,

so I hope you’ve enjoyed this ridiculously 
long video, and until next time, cheers.

