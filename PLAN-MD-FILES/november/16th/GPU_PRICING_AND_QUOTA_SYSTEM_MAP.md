# GPU Pricing and Quota System Map - Complete Technical Reference

**Date**: 2025-11-16
**Status**: Comprehensive code flow analysis
**Version**: 2.0 - Expanded with full call chains and data flows

---

## ğŸ“Š Table of Contents

1. [System Overview](#system-overview)
2. [GPU Quota System](#1ï¸âƒ£-gpu-quota-system)
3. [GPU Pricing System](#2ï¸âƒ£-gpu-pricing-system)
4. [Complete Code Flows](#complete-code-flows)
5. [Data Structures](#data-structures)
6. [Configuration & Constants](#configuration--constants)
7. [Error Handling Patterns](#error-handling-patterns)
8. [Quick Reference Tables](#quick-reference-tables)

---

## System Overview

### Two Distinct Systems

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ARR-COC INFRASTRUCTURE                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   GPU QUOTA SYSTEM        â”‚  â”‚   GPU PRICING SYSTEM     â”‚   â”‚
â”‚  â”‚   (Infrastructure Mgmt)   â”‚  â”‚   (Cost Tracking)        â”‚   â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”‚
â”‚  â”‚                           â”‚  â”‚                          â”‚   â”‚
â”‚  â”‚ â€¢ Check quota availabilityâ”‚  â”‚ â€¢ Fetch live prices      â”‚   â”‚
â”‚  â”‚ â€¢ Auto-request if zero    â”‚  â”‚ â€¢ Store in Artifact Reg  â”‚   â”‚
â”‚  â”‚ â€¢ Validate before launch  â”‚  â”‚ â€¢ Calculate build costs  â”‚   â”‚
â”‚  â”‚ â€¢ Show manual instructionsâ”‚  â”‚ â€¢ Track campaign stats   â”‚   â”‚
â”‚  â”‚                           â”‚  â”‚                          â”‚   â”‚
â”‚  â”‚ Used by: Launch validationâ”‚  â”‚ Used by: MECHA, tracking â”‚   â”‚
â”‚  â”‚                           â”‚  â”‚                          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Insight**: These systems are **independent** - quota checks infrastructure access, pricing tracks costs.

---

## 1ï¸âƒ£ GPU QUOTA SYSTEM

### Purpose
Ensure sufficient GPU quota exists before launching Vertex AI training jobs.

### Architecture Overview

```
                    GPU QUOTA VALIDATION FLOW

User runs: python training/cli.py launch
                â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ launch_training_job() - training/cli/launch/core.py:750      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  Step 1.5 (line 815): Auto-request GPU quota                 â”‚
â”‚     â†“                                                         â”‚
â”‚  _auto_request_gpu_quota(config, region, status)             â”‚
â”‚     â”‚                                                         â”‚
â”‚     â”œâ”€â†’ Returns "EXISTS" â†’ Proceed with launch âœ“             â”‚
â”‚     â”œâ”€â†’ Returns "REQUESTED" â†’ HALT launch, wait for approval â”‚
â”‚     â””â”€â†’ Returns "FAILED" â†’ Proceed (will fail at Vertex AI)  â”‚
â”‚                                                               â”‚
â”‚  [Step 1.6 REMOVED - old verification deleted 2025-11-16]    â”‚
â”‚                                                               â”‚
â”‚  Step 2: Submit to W&B queue                                 â”‚
â”‚  Step 3-7: Setup infrastructure                              â”‚
â”‚  Step 8: Launch training job                                 â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Detailed Function: `_auto_request_gpu_quota()`

**Location**: `training/cli/launch/core.py:3913-4083`

**Function Signature**:
```python
def _auto_request_gpu_quota(config: Dict, region: str, status) -> str
```

**Returns**:
- `"EXISTS"` - Quota available (>0), proceed
- `"REQUESTED"` - Quota auto-requested, HALT launch
- `"FAILED"` - Auto-request failed, proceed to manual

**Complete Code Flow**:

```python
_auto_request_gpu_quota(config, region, status)
    â”‚
    â”œâ”€ Line 3930: Extract config values
    â”‚   â€¢ project_id = config["GCP_PROJECT_ID"]
    â”‚   â€¢ gpu_type = config["WANDB_LAUNCH_ACCELERATOR_TYPE"]  # "NVIDIA_TESLA_T4"
    â”‚   â€¢ gpu_count = config["WANDB_LAUNCH_ACCELERATOR_COUNT"]  # "1"
    â”‚   â€¢ use_spot = config["WANDB_LAUNCH_USE_PREEMPTIBLE"]  # "true"
    â”‚
    â”œâ”€ Line 3937: Map GPU type to Vertex AI quota metric
    â”‚   gpu_quota_metrics = {
    â”‚       "NVIDIA_TESLA_T4": "nvidia_t4_gpus",
    â”‚       "NVIDIA_TESLA_A100": "nvidia_a100_gpus",
    â”‚       "NVIDIA_A100_80GB": "nvidia_a100_80gb_gpus",
    â”‚       "NVIDIA_H100": "nvidia_h100_gpus",
    â”‚       "NVIDIA_H100_80GB": "nvidia_h100_80gb_gpus",
    â”‚       "NVIDIA_H200": "nvidia_h200_gpus",
    â”‚       "NVIDIA_L4": "nvidia_l4_gpus",
    â”‚   }
    â”‚   quota_metric_suffix = gpu_quota_metrics[gpu_type]
    â”‚   quota_metric = f"aiplatform.googleapis.com/custom_model_training_{suffix}"
    â”‚   # Result: "aiplatform.googleapis.com/custom_model_training_nvidia_t4_gpus"
    â”‚
    â”œâ”€ Line 3962: STEP 1 - Quick Check (Compute Engine quotas as approximation)
    â”‚   â”‚
    â”‚   â”œâ”€ Run: gcloud compute regions describe {region} --format=json
    â”‚   â”‚
    â”‚   â”œâ”€ Parse quotas from response
    â”‚   â”‚   region_info = json.loads(result.stdout)
    â”‚   â”‚   quotas = region_info["quotas"]
    â”‚   â”‚
    â”‚   â”œâ”€ Line 3996: Map to Compute Engine quota names
    â”‚   â”‚   quota_map = {
    â”‚   â”‚       "NVIDIA_H200": "NVIDIA_H200_GPUS",
    â”‚   â”‚       "NVIDIA_H100": "NVIDIA_H100_GPUS",
    â”‚   â”‚       "NVIDIA_TESLA_T4": "NVIDIA_T4_GPUS",
    â”‚   â”‚       ...
    â”‚   â”‚   }
    â”‚   â”‚   gcp_quota_metric = quota_map[gpu_type]
    â”‚   â”‚   if use_spot:
    â”‚   â”‚       gcp_quota_metric = f"PREEMPTIBLE_{gcp_quota_metric}"
    â”‚   â”‚   # Result: "PREEMPTIBLE_NVIDIA_T4_GPUS"
    â”‚   â”‚
    â”‚   â”œâ”€ Line 4010: Search for matching quota
    â”‚   â”‚   for quota in quotas:
    â”‚   â”‚       if quota["metric"] == gcp_quota_metric:
    â”‚   â”‚           limit = quota["limit"]
    â”‚   â”‚           if limit > 0:
    â”‚   â”‚               return "EXISTS" âœ“  # Quota available!
    â”‚   â”‚
    â”‚   â””â”€ If limit == 0 or not found â†’ Continue to STEP 2
    â”‚
    â”œâ”€ Line 4032: STEP 2 - Auto-request Vertex AI quota
    â”‚   â”‚
    â”‚   â”œâ”€ Run: gcloud alpha compute regions update-quota
    â”‚   â”‚        --project={project_id}
    â”‚   â”‚        --region={region}
    â”‚   â”‚        --quota-metric={quota_metric}  # Vertex AI metric!
    â”‚   â”‚        --new-limit={gpu_count}
    â”‚   â”‚
    â”‚   â”œâ”€ Line 4049: If successful
    â”‚   â”‚   status("âœ… GPU QUOTA REQUEST SUBMITTED!")
    â”‚   â”‚   status(f"   GPU Type: {gpu_type}")
    â”‚   â”‚   status(f"   Requested: {gpu_count} GPU(s)")
    â”‚   â”‚   status("ğŸ“§ Google will email when approved (1-2 days)")
    â”‚   â”‚   return "REQUESTED"  # HALT launch!
    â”‚   â”‚
    â”‚   â””â”€ Line 4063: If failed
    â”‚       status("âš ï¸ Auto-request failed")
    â”‚       status(f"Error: {stderr[:200]}")
    â”‚       return "FAILED"  # Proceed to manual verification
    â”‚
    â””â”€ Line 4077: Exception handling
        return "FAILED"  # Any error â†’ proceed to manual
```

**Critical Notes**:

1. **Two Quota Systems**: Line 3991 comment explains this clearly:
   ```python
   # NOTE: This checks COMPUTE ENGINE quotas to see if quota EXISTS
   # But the actual auto-request (line 4034) uses VERTEX AI quotas
   # We check Compute Engine first because it's faster/simpler
   # If Compute Engine quota > 0, we assume Vertex AI quota also exists
   # This is an approximation - the two quota systems are separate!
   ```

2. **Why Approximation Works**:
   - Compute Engine check is fast (single API call)
   - If CE quota exists, VA quota usually exists too
   - If CE quota is zero, VA quota is definitely zero
   - Auto-request uses **correct** Vertex AI quota metric

3. **Quota Namespace Difference**:
   ```
   Compute Engine:  PREEMPTIBLE_NVIDIA_T4_GPUS
   Vertex AI:       aiplatform.googleapis.com/custom_model_training_nvidia_t4_gpus
   ```

### Launch Integration

**File**: `training/cli/launch/core.py:815-830`

```python
# Step 1.5: Auto-request GPU quota if needed
quota_status = _auto_request_gpu_quota(config, region, status)

if quota_status == "REQUESTED":
    # Quota just requested - HALT launch!
    status("")
    status("ğŸ›‘ LAUNCH HALTED - GPU quota requested, awaiting approval")
    status("")
    status("Next steps:")
    status("1. Wait 1-2 business days for Google to approve")
    status("2. Check email for approval notification")
    status("3. Run 'python training/cli.py launch' again")
    status("")
    return False  # Abort launch

# If quota_status == "EXISTS" or "FAILED", continue with launch
# "FAILED" means auto-request didn't work, but job may still succeed
# (user might have manually requested quota earlier)
```

### Deleted System (2025-11-16)

**Old Function**: `_verify_gpu_quota()` - **DELETED**

**Location**: Previously at `training/cli/launch/core.py:4078-4255` (178 lines)

**Why Deleted**:
```python
# _verify_gpu_quota() DELETED (2025-11-16)
#
# This function checked COMPUTE ENGINE quotas (NVIDIA_T4_GPUS, PREEMPTIBLE_NVIDIA_T4_GPUS)
# But Vertex AI Custom Training uses VERTEX AI quotas (custom_model_training_nvidia_t4_gpus)
# These are COMPLETELY DIFFERENT quota namespaces!
#
# Problem: Validation passed on wrong quota â†’ submission failed on correct quota
# Solution: Rely on _auto_request_gpu_quota() (line 3913) which checks CORRECT quotas
#
# See detailed analysis in:
# - VERTEX_AI_GPU_QUOTA_BUG_REPORT.md
# - GPU_QUOTA_SYSTEMS_ANALYSIS.md
```

**What It Did (Historical Reference)**:
1. Checked **Compute Engine** quotas using `gcloud compute regions describe`
2. Validated quota against requested GPU count
3. Showed GO/NO-GO message
4. Called `show_gpu_quota_instructions()` on failure

**The Bug**:
- Checked `PREEMPTIBLE_NVIDIA_T4_GPUS` (Compute Engine) âŒ
- Vertex AI uses `custom_model_training_nvidia_t4_gpus` âœ“
- Validation passed (CE quota = 1) but Vertex AI failed (VA quota = 0)

### Manual Instructions (Unused Placeholder)

**File**: `training/cli/shared/gpu_quota_instruct.py`

**Status**: Code exists but **NOT CALLED** anywhere

**Function**: `show_gpu_quota_instructions()`

**Lines**: 97-153

**What It Would Do** (if called):
```python
def show_gpu_quota_instructions(
    project_id, region, gpu_type, gpu_count, use_preemptible, status
):
    # Show manual quota request instructions
    status("ğŸ’¡ MANUAL QUOTA REQUEST (if needed):")
    status(f"1. Visit: https://console.cloud.google.com/iam-admin/quotas?project={project_id}")

    if use_preemptible:
        status(f"2. Search for: Preemptible NVIDIA {gpu_name} GPUs")  # âŒ WRONG!
    else:
        status(f"2. Search for: NVIDIA {gpu_name} GPUs")  # âŒ WRONG!

    status(f"3. Select region: {region}")
    status(f"4. Request: {gpu_count} GPU(s)")
```

**BUG in Instructions** (Lines 129-136):
- Tells users to search for **Compute Engine quotas** âŒ
- Should search for **Vertex AI quotas** âœ“
- Example fix:
  ```python
  # Wrong:
  status("2. Search for: Preemptible NVIDIA T4 GPUs")

  # Correct:
  status("2. Search for: Custom model training preemptible NVIDIA T4 GPUs")
  ```

**Future Enhancement** (Lines 7-95):
- Epic mythological narrative planned (ORDEAL OF DIVINE THUNDER)
- Zeus as GPU quota gatekeeper
- Hermes Trismegistus providing ridiculous alchemical advice
- Enkidu wandering in from C3 quota saga (crossover cameo)
- See file comments for complete mythology design

### Quota Data Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      QUOTA CHECK FLOW                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  config["WANDB_LAUNCH_ACCELERATOR_TYPE"] = "NVIDIA_TESLA_T4"    â”‚
â”‚  config["WANDB_LAUNCH_ACCELERATOR_COUNT"] = "1"                 â”‚
â”‚  config["WANDB_LAUNCH_USE_PREEMPTIBLE"] = "true"                â”‚
â”‚                      â†“                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ _auto_request_gpu_quota()                               â”‚   â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”‚
â”‚  â”‚                                                         â”‚   â”‚
â”‚  â”‚ Step 1: Map GPU type â†’ CE quota name                   â”‚   â”‚
â”‚  â”‚   "NVIDIA_TESLA_T4" â†’ "NVIDIA_T4_GPUS"                  â”‚   â”‚
â”‚  â”‚   + use_spot â†’ "PREEMPTIBLE_NVIDIA_T4_GPUS"            â”‚   â”‚
â”‚  â”‚                                                         â”‚   â”‚
â”‚  â”‚ Step 2: Check CE quota (approximation)                 â”‚   â”‚
â”‚  â”‚   gcloud compute regions describe                      â”‚   â”‚
â”‚  â”‚   â†’ quotas[metric="PREEMPTIBLE_NVIDIA_T4_GPUS"]        â”‚   â”‚
â”‚  â”‚   â†’ limit = 1.0 âœ“ (exists!)                            â”‚   â”‚
â”‚  â”‚   â†’ return "EXISTS"                                     â”‚   â”‚
â”‚  â”‚                                                         â”‚   â”‚
â”‚  â”‚ [OR if limit == 0]                                      â”‚   â”‚
â”‚  â”‚                                                         â”‚   â”‚
â”‚  â”‚ Step 3: Map GPU type â†’ VA quota name                   â”‚   â”‚
â”‚  â”‚   "NVIDIA_TESLA_T4" â†’ "nvidia_t4_gpus"                  â”‚   â”‚
â”‚  â”‚   â†’ "aiplatform.googleapis.com/                        â”‚   â”‚
â”‚  â”‚       custom_model_training_nvidia_t4_gpus"            â”‚   â”‚
â”‚  â”‚                                                         â”‚   â”‚
â”‚  â”‚ Step 4: Auto-request VA quota                          â”‚   â”‚
â”‚  â”‚   gcloud alpha compute regions update-quota            â”‚   â”‚
â”‚  â”‚   --quota-metric=aiplatform.googleapis.com/...         â”‚   â”‚
â”‚  â”‚   â†’ Success: return "REQUESTED" (HALT!)                â”‚   â”‚
â”‚  â”‚   â†’ Failure: return "FAILED" (continue)                â”‚   â”‚
â”‚  â”‚                                                         â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                      â†“                                          â”‚
â”‚  Launch flow decision:                                          â”‚
â”‚    "EXISTS" â†’ Continue launch âœ“                                 â”‚
â”‚    "REQUESTED" â†’ HALT launch, wait for approval âœ‹              â”‚
â”‚    "FAILED" â†’ Continue anyway (may fail at Vertex AI) âš ï¸        â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2ï¸âƒ£ GPU PRICING SYSTEM

### Purpose
Track infrastructure costs for billing, accounting, and campaign statistics. **NOT** for showing user-facing cost estimates.

### Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PRICING INFRASTRUCTURE                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ Cloud        â”‚â”€â”€â†’â”‚ Cloud        â”‚â”€â”€â†’â”‚ Artifact         â”‚    â”‚
â”‚  â”‚ Scheduler    â”‚   â”‚ Function     â”‚   â”‚ Registry         â”‚    â”‚
â”‚  â”‚              â”‚   â”‚              â”‚   â”‚                  â”‚    â”‚
â”‚  â”‚ Every 20 min â”‚   â”‚ Fetch GCP    â”‚   â”‚ Store pricing    â”‚    â”‚
â”‚  â”‚              â”‚   â”‚ Billing API  â”‚   â”‚ JSON (generic)   â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                â†“                â”‚
â”‚                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚                         â”‚ Consumer Code                    â”‚    â”‚
â”‚                         â”‚ - MECHA (battle pricing display) â”‚    â”‚
â”‚                         â”‚ - Campaign stats (cost tracking) â”‚    â”‚
â”‚                         â”‚ - Launch core (build costs)      â”‚    â”‚
â”‚                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Configuration & Constants

**File**: `training/cli/shared/pricing_config.py`

```python
# Project config (from .training file)
PROJECT_ID = "weight-and-biases-476906"
REGION = "us-central1"

# Pricing infrastructure names
FUNCTION_NAME = "arr-coc-pricing-runner"
SCHEDULER_JOB = "arr-coc-pricing-scheduler"
SCHEDULER_INTERVAL_MINUTES = 20  # */20 * * * *
REPOSITORY = "arr-coc-pricing"
PACKAGE = "gcp-pricing"

# Pricing data schema (validation)
PRICING_SCHEMA = {
    "updated": {
        "type": "timestamp",
        "required": True,
        "should_have_data": False
    },
    "c3_machines": {
        "type": "dict",
        "required": True,
        "should_have_data": True  # Must have regions!
    },
    "e2_machines": {
        "type": "dict",
        "required": True,
        "should_have_data": True
    },
    "gpus_spot": {
        "type": "dict",
        "required": True,
        "should_have_data": True
    },
    "gpus_ondemand": {
        "type": "dict",
        "required": True,
        "should_have_data": True
    },
}
```

### Setup Flow (Complete Walkthrough)

**Entry Point**: `training/cli/setup/pricing_setup.py:96`

```python
def setup_pricing_infrastructure(status_callback) -> bool
```

**Complete Flow**:

```
setup_pricing_infrastructure(status)
    â”‚
    â”œâ”€ Line 101: PHASE 0 - Create Repository
    â”‚   â”‚
    â”‚   â””â”€ create_pricing_repository(status)
    â”‚       â”‚
    â”‚       â”œâ”€ Check if exists:
    â”‚       â”‚   gcloud artifacts repositories describe arr-coc-pricing
    â”‚       â”‚   â†’ Exists? Return early (idempotent)
    â”‚       â”‚
    â”‚       â””â”€ Create generic repository:
    â”‚           gcloud artifacts repositories create arr-coc-pricing
    â”‚               --repository-format=generic
    â”‚               --location=us-central1
    â”‚               --description="ARR-COC pricing data storage"
    â”‚
    â”œâ”€ Line 105: PHASE 1 - Grant OIDC Permissions
    â”‚   â”‚
    â”‚   â””â”€ grant_actAs_permission(status)  # Silent
    â”‚       â”‚
    â”‚       â”œâ”€ Get current user:
    â”‚       â”‚   gcloud config get-value account
    â”‚       â”‚   â†’ user_email
    â”‚       â”‚
    â”‚       â”œâ”€ Define service account:
    â”‚       â”‚   {PROJECT_ID}@appspot.gserviceaccount.com
    â”‚       â”‚
    â”‚       â”œâ”€ Check if permission already exists (idempotent):
    â”‚       â”‚   gcloud iam service-accounts get-iam-policy {sa} --format=json
    â”‚       â”‚   â†’ Parse bindings
    â”‚       â”‚   â†’ If "roles/iam.serviceAccountUser" + "user:{email}" exists
    â”‚       â”‚      â†’ return (True, None)  # Already granted!
    â”‚       â”‚
    â”‚       â”œâ”€ Grant permission:
    â”‚       â”‚   gcloud iam service-accounts add-iam-policy-binding
    â”‚       â”‚       {sa}
    â”‚       â”‚       --member=user:{user_email}
    â”‚       â”‚       --role=roles/iam.serviceAccountUser
    â”‚       â”‚       --condition=expression=resource.service=="cloudscheduler.googleapis.com",
    â”‚       â”‚                    title=OIDCSchedulerOnly
    â”‚       â”‚
    â”‚       â””â”€ Retry with backoff (4 attempts: 0s, 1s, 4s, 8s)
    â”‚           â†’ retry_with_backoff(try_grant_permission, max_attempts=4)
    â”‚
    â”œâ”€ Line 109: PHASE 2 - Deploy Cloud Function
    â”‚   â”‚
    â”‚   â””â”€ deploy_cloud_function(status)
    â”‚       â”‚
    â”‚       â”œâ”€ Enable APIs:
    â”‚       â”‚   â€¢ cloudfunctions.googleapis.com
    â”‚       â”‚   â€¢ cloudbuild.googleapis.com
    â”‚       â”‚   â€¢ cloudbilling.googleapis.com
    â”‚       â”‚
    â”‚       â”œâ”€ Deploy function (with streaming output):
    â”‚       â”‚   gcloud functions deploy arr-coc-pricing-runner
    â”‚       â”‚       --gen2
    â”‚       â”‚       --region=us-central1
    â”‚       â”‚       --runtime=python312
    â”‚       â”‚       --entry-point=fetch_pricing
    â”‚       â”‚       --source={function_dir}
    â”‚       â”‚       --trigger-http
    â”‚       â”‚       --allow-unauthenticated
    â”‚       â”‚       --timeout=540s
    â”‚       â”‚       --memory=512MB
    â”‚       â”‚       --max-instances=1
    â”‚       â”‚
    â”‚       â”œâ”€ Timeout: 10 minutes per attempt
    â”‚       â”‚
    â”‚       â”œâ”€ Retry logic (4 attempts with 1s, 4s, 8s backoff)
    â”‚       â”‚
    â”‚       â”œâ”€ Stream output line-by-line:
    â”‚       â”‚   for line in process.stdout:
    â”‚       â”‚       sys.stdout.write(f"               {line}")
    â”‚       â”‚
    â”‚       â””â”€ Verify deployment:
    â”‚           gcloud functions describe arr-coc-pricing-runner
    â”‚               --format=value(state)
    â”‚           â†’ Must be "ACTIVE"
    â”‚
    â”œâ”€ Line 113: PHASE 3 - Bootstrap Pricing Data
    â”‚   â”‚
    â”‚   â””â”€ bootstrap_pricing(status)
    â”‚       â”‚
    â”‚       â”œâ”€ Try to fetch existing pricing from Artifact Registry:
    â”‚       â”‚   â”‚
    â”‚       â”‚   â””â”€ artifact_pricing.fetch_pricing_no_save()
    â”‚       â”‚       â”œâ”€ Get latest version via HTTP:
    â”‚       â”‚       â”‚   GET https://artifactregistry.googleapis.com/v1/
    â”‚       â”‚       â”‚       projects/{PROJECT}/locations/{LOCATION}/
    â”‚       â”‚       â”‚       repositories/{REPO}/packages/{PACKAGE}/versions
    â”‚       â”‚       â”‚       ?pageSize=1&orderBy=createTime desc
    â”‚       â”‚       â”‚   â†’ version: "1.0.20251116-143052"
    â”‚       â”‚       â”‚
    â”‚       â”‚       â””â”€ Download via gcloud CLI:
    â”‚       â”‚           gcloud artifacts generic download
    â”‚       â”‚               --package=gcp-pricing
    â”‚       â”‚               --version={version}
    â”‚       â”‚               --destination={tmpdir}
    â”‚       â”‚           â†’ Temp file: /var/folders/.../gcp-live-pricing.json
    â”‚       â”‚           â†’ Load JSON â†’ return (pricing_data, version, size_kb)
    â”‚       â”‚
    â”‚       â”œâ”€ If pricing found â†’ Validate schema:
    â”‚       â”‚   â”‚
    â”‚       â”‚   â”œâ”€ Get expected fields:
    â”‚       â”‚   â”‚   pricing_config.get_required_fields()
    â”‚       â”‚   â”‚   â†’ {"updated": False, "c3_machines": True, ...}
    â”‚       â”‚   â”‚
    â”‚       â”‚   â”œâ”€ Check each field:
    â”‚       â”‚   â”‚   for field, should_have_data in expected_fields.items():
    â”‚       â”‚   â”‚       if field not in existing_data:
    â”‚       â”‚   â”‚           missing_fields.append(f"{field} (missing)")
    â”‚       â”‚   â”‚       elif should_have_data and len(existing_data[field]) == 0:
    â”‚       â”‚   â”‚           missing_fields.append(f"{field} (empty)")
    â”‚       â”‚   â”‚
    â”‚       â”‚   â”œâ”€ If schema invalid:
    â”‚       â”‚   â”‚   raise ValueError(f"Schema mismatch: {missing_fields}")
    â”‚       â”‚   â”‚   â†’ Triggers fresh fetch
    â”‚       â”‚   â”‚
    â”‚       â”‚   â””â”€ Check age:
    â”‚       â”‚       age_minutes = get_pricing_age_minutes(existing_data)
    â”‚       â”‚       if age_minutes < SCHEDULER_INTERVAL_MINUTES:  # < 20 min
    â”‚       â”‚           â†’ Use existing âœ“
    â”‚       â”‚           â†’ Trigger Cloud Function for first run
    â”‚       â”‚           â†’ return
    â”‚       â”‚       else:
    â”‚       â”‚           â†’ Fetch fresh (stale)
    â”‚       â”‚
    â”‚       â”œâ”€ If pricing missing or stale â†’ Fetch fresh:
    â”‚       â”‚   â”‚
    â”‚       â”‚   â””â”€ _fetch_pricing_inline(status)
    â”‚       â”‚       â”‚
    â”‚       â”‚       â”œâ”€ Get OAuth token:
    â”‚       â”‚       â”‚   gcloud auth print-access-token
    â”‚       â”‚       â”‚
    â”‚       â”‚       â”œâ”€ Query GCP Cloud Billing API:
    â”‚       â”‚       â”‚   GET https://cloudbilling.googleapis.com/v1/
    â”‚       â”‚       â”‚       services/6F81-5844-456A/skus
    â”‚       â”‚       â”‚       ?pageSize=500
    â”‚       â”‚       â”‚
    â”‚       â”‚       â”‚   Page through results (nextPageToken)
    â”‚       â”‚       â”‚   â†’ ~30,000 SKUs total
    â”‚       â”‚       â”‚   â†’ Show progress every 5000 SKUs
    â”‚       â”‚       â”‚
    â”‚       â”‚       â”œâ”€ For each SKU, extract:
    â”‚       â”‚       â”‚   â€¢ Price: units + (nanos / 1e9)
    â”‚       â”‚       â”‚   â€¢ Description
    â”‚       â”‚       â”‚   â€¢ SKU ID
    â”‚       â”‚       â”‚   â€¢ Usage type (Spot, Preemptible, OnDemand, Commit)
    â”‚       â”‚       â”‚   â€¢ Regions
    â”‚       â”‚       â”‚
    â”‚       â”‚       â”œâ”€ Filter and categorize:
    â”‚       â”‚       â”‚   â”‚
    â”‚       â”‚       â”‚   â”œâ”€ C3 machines (spot):
    â”‚       â”‚       â”‚   â”‚   if "c3" in desc and "spot" in desc:
    â”‚       â”‚       â”‚   â”‚       pricing_data["c3_machines"][region]["cpu_per_core_spot"].append(sku)
    â”‚       â”‚       â”‚   â”‚       pricing_data["c3_machines"][region]["ram_per_gb_spot"].append(sku)
    â”‚       â”‚       â”‚   â”‚
    â”‚       â”‚       â”‚   â”œâ”€ E2 machines (on-demand):
    â”‚       â”‚       â”‚   â”‚   if "e2" in desc and "instance" in desc:
    â”‚       â”‚       â”‚   â”‚       pricing_data["e2_machines"][region]["cpu_per_core_ondemand"].append(sku)
    â”‚       â”‚       â”‚   â”‚       pricing_data["e2_machines"][region]["ram_per_gb_ondemand"].append(sku)
    â”‚       â”‚       â”‚   â”‚
    â”‚       â”‚       â”‚   â””â”€ GPUs (all types):
    â”‚       â”‚       â”‚       if "gpu" in desc or "tpu" in desc:
    â”‚       â”‚       â”‚           if "Spot" or "Preemptible" in desc:
    â”‚       â”‚       â”‚               pricing_data["gpus_spot"][region].append(sku)
    â”‚       â”‚       â”‚           else:
    â”‚       â”‚       â”‚               pricing_data["gpus_ondemand"][region].append(sku)
    â”‚       â”‚       â”‚               # Includes: OnDemand, 1-Year Commit, 3-Year Commit
    â”‚       â”‚       â”‚
    â”‚       â”‚       â””â”€ Return pricing_data with complete SKU lists
    â”‚       â”‚
    â”‚       â”œâ”€ Sort all pricing lists (cheapest first):
    â”‚       â”‚   for region_data in pricing_data["c3_machines"].values():
    â”‚       â”‚       region_data["cpu_per_core_spot"].sort(key=lambda x: x["price"])
    â”‚       â”‚       region_data["ram_per_gb_spot"].sort(key=lambda x: x["price"])
    â”‚       â”‚   # ... same for e2_machines, gpus_spot, gpus_ondemand
    â”‚       â”‚
    â”‚       â”œâ”€ Count and display stats:
    â”‚       â”‚   status(f"  â€¢ C3 machines (spot): {c3_regions} regions")
    â”‚       â”‚   status(f"  â€¢ E2 machines (on-demand): {e2_regions} regions")
    â”‚       â”‚   status(f"  â€¢ GPUs (spot): {gpu_spot_regions} regions - T4=45, L4=23, ...")
    â”‚       â”‚   status(f"  â€¢ GPUs (on-demand): {gpu_ondemand_regions} regions - ...")
    â”‚       â”‚
    â”‚       â”œâ”€ Upload to Artifact Registry:
    â”‚       â”‚   artifact_pricing.upload_pricing_to_artifact_registry(pricing_data)
    â”‚       â”‚   â”‚
    â”‚       â”‚   â””â”€ Generate version:
    â”‚       â”‚       timestamp = datetime.now().strftime("%Y%m%d-%H%M%S")
    â”‚       â”‚       version = f"1.0.{timestamp}"  # "1.0.20251116-143052"
    â”‚       â”‚
    â”‚       â”‚       Save to temp file â†’ gcp-live-pricing.json
    â”‚       â”‚
    â”‚       â”‚       gcloud artifacts generic upload
    â”‚       â”‚           --package=gcp-pricing
    â”‚       â”‚           --version={version}
    â”‚       â”‚           --source={temp_file}
    â”‚       â”‚
    â”‚       â”‚       Temp file auto-deleted by context manager
    â”‚       â”‚
    â”‚       â””â”€ Trigger Cloud Function (first run):
    â”‚           _trigger_and_verify_function(status)
    â”‚           â”‚
    â”‚           â”œâ”€ Trigger (async):
    â”‚           â”‚   subprocess.Popen([
    â”‚           â”‚       "gcloud", "functions", "call",
    â”‚           â”‚       "arr-coc-pricing-runner",
    â”‚           â”‚       "--gen2", "--region=us-central1"
    â”‚           â”‚   ])
    â”‚           â”‚
    â”‚           â””â”€ Watch logs for startup (90s timeout):
    â”‚               while elapsed < 90s:
    â”‚                   gcloud logging read
    â”‚                       'resource.type="cloud_run_revision"
    â”‚                        AND textPayload:"PRICING_RUNNER_STARTED"'
    â”‚
    â”‚                   if found:
    â”‚                       status("âœ“ Cloud Function verified")
    â”‚                       return
    â”‚
    â”‚                   sleep(2s)
    â”‚
    â”‚               # Timeout OK - function may still be cold starting
    â”‚
    â””â”€ Line 116: PHASE 4 - Create Cloud Scheduler
        â”‚
        â””â”€ create_scheduler(status)
            â”‚
            â”œâ”€ Enable API:
            â”‚   gcloud services enable cloudscheduler.googleapis.com
            â”‚
            â”œâ”€ Get function URL:
            â”‚   gcloud functions describe arr-coc-pricing-runner
            â”‚       --format=value(serviceConfig.uri)
            â”‚   â†’ function_url
            â”‚
            â”œâ”€ Check if scheduler exists and is correctly configured:
            â”‚   gcloud scheduler jobs describe arr-coc-pricing-scheduler
            â”‚       --format=json
            â”‚
            â”‚   Expected config:
            â”‚       schedule: "*/20 * * * *"  (every 20 min)
            â”‚       uri: {function_url}
            â”‚       serviceAccountEmail: {PROJECT}@appspot.gserviceaccount.com
            â”‚       state: "ENABLED"
            â”‚
            â”‚   If config matches â†’ skip creation (idempotent)
            â”‚   If config wrong â†’ delete and recreate
            â”‚
            â”œâ”€ Create scheduler job:
            â”‚   gcloud scheduler jobs create http arr-coc-pricing-scheduler
            â”‚       --location=us-central1
            â”‚       --schedule="*/20 * * * *"
            â”‚       --uri={function_url}
            â”‚       --http-method=GET
            â”‚       --oidc-service-account-email={sa}
            â”‚       --oidc-token-audience={function_url}
            â”‚
            â””â”€ Return success
```

### Teardown Flow (Complete Walkthrough)

**Entry Point**: `training/cli/teardown/pricing_teardown.py:95`

```python
def teardown_pricing_infrastructure(status_callback)
```

**Complete Flow**:

```
teardown_pricing_infrastructure(status)
    â”‚
    â”œâ”€ Line 103: PHASE 1 - Delete Cloud Scheduler
    â”‚   â”‚
    â”‚   â””â”€ delete_scheduler(status)
    â”‚       â”‚
    â”‚       â””â”€ Retry with backoff (4 attempts):
    â”‚           gcloud scheduler jobs delete arr-coc-pricing-scheduler
    â”‚               --location=us-central1
    â”‚               --quiet
    â”‚
    â”‚           Success or "not found" â†’ (True, None)
    â”‚           Other error â†’ (False, error_msg) â†’ retry
    â”‚
    â”œâ”€ Line 107: PHASE 2 - Delete Cloud Function
    â”‚   â”‚
    â”‚   â””â”€ delete_cloud_function(status)
    â”‚       â”‚
    â”‚       â””â”€ Retry with backoff (4 attempts):
    â”‚           gcloud functions delete arr-coc-pricing-runner
    â”‚               --gen2
    â”‚               --region=us-central1
    â”‚               --quiet
    â”‚
    â”‚           Success or "not found" â†’ (True, None)
    â”‚           Other error â†’ (False, error_msg) â†’ retry
    â”‚
    â”œâ”€ Line 111: PHASE 3 - Revoke OIDC Permissions
    â”‚   â”‚
    â”‚   â””â”€ revoke_actAs_permission(status)  # Silent
    â”‚       â”‚
    â”‚       â”œâ”€ Get current user:
    â”‚       â”‚   gcloud config get-value account
    â”‚       â”‚
    â”‚       â””â”€ Remove permission:
    â”‚           gcloud iam service-accounts remove-iam-policy-binding
    â”‚               {sa}
    â”‚               --member=user:{email}
    â”‚               --role=roles/iam.serviceAccountUser
    â”‚               --condition=expression=resource.service=="cloudscheduler.googleapis.com",
    â”‚                            title=OIDCSchedulerOnly
    â”‚
    â”‚           Ignore "not found" or "no binding" errors
    â”‚
    â”œâ”€ Line 115: PHASE 4 - Disable Cloud Billing API
    â”‚   â”‚
    â”‚   â””â”€ disable_cloudbilling_api(status)  # Silent
    â”‚       â”‚
    â”‚       â””â”€ gcloud services disable cloudbilling.googleapis.com
    â”‚           â†’ May fail if still in use (OK to continue)
    â”‚
    â””â”€ Line 119: PRESERVE Artifact Registry Repository âœ“
        status("â„¹ Pricing repository preserved (historical data intact)")

        # NOTE: Repository NOT deleted!
        # Contains historical pricing data
        # Function cleanup_artifact_registry() exists but NOT called
```

### Pricing Data Access (Consumer Patterns)

**Pattern 1: MECHA Battle Epic** (Display pricing in battle animations)

**File**: `training/cli/launch/mecha/mecha_battle_epic.py:258, 288`

```python
from ...shared.artifact_pricing import get_spot_price

# Get region pricing
region_pricing = pricing["c3_machines"].get(region, {})
cpu_skus = region_pricing.get("cpu_per_core_spot", [])

# Extract cheapest price
cpu_per_core = get_spot_price(cpu_skus)
# â†’ Returns: cpu_skus[0]["price"] if exists (cheapest, since sorted)

# Display in battle text
status(f"âš¡ L4 SPOT PRICE: ${price:.2f}/hr âš¡")
```

**Pattern 2: Launch Core** (Calculate build costs for campaign stats)

**File**: `training/cli/shared/pricing/get_live_prices.py:10-58`

```python
def get_live_price_for_launch(machine_type: str, region: str) -> float:
    # Fetch pricing from Artifact Registry
    pricing_data, _, _ = fetch_pricing_no_save()

    # C3 machines (MECHA worker pool - spot pricing)
    if machine_type.startswith("c3-standard-"):
        vcpus = int(machine_type.split("-")[-1])  # "c3-standard-176" â†’ 176
        ram_gb = vcpus * 4  # C3: 4 GB RAM per vCPU

        c3_data = pricing_data["c3_machines"][region]
        cpu_skus = c3_data["cpu_per_core_spot"]
        ram_skus = c3_data["ram_per_gb_spot"]

        cpu_price = get_spot_price(cpu_skus)  # $/core/hour
        ram_price = get_spot_price(ram_skus)  # $/GB/hour

        return (vcpus * cpu_price) + (ram_gb * ram_price)

    # E2 machines (Cloud Build default - on-demand pricing)
    elif machine_type == "E2_HIGHCPU_8":
        vcpus = 8
        ram_gb = 8  # E2_HIGHCPU: 1 GB RAM per vCPU

        e2_data = pricing_data["e2_machines"][region]
        cpu_skus = e2_data["cpu_per_core_ondemand"]
        ram_skus = e2_data["ram_per_gb_ondemand"]

        cpu_price = get_standard_price(cpu_skus)  # $/core/hour (on-demand)
        ram_price = get_standard_price(ram_skus)  # $/GB/hour (on-demand)

        return (vcpus * cpu_price) + (ram_gb * ram_price)

    else:
        return 0.0  # Unknown machine type
```

**Pattern 3: Generic Pricing Extraction**

**File**: `training/cli/shared/artifact_pricing.py:229-397`

```python
# Extract cheapest spot/preemptible price
def get_spot_price(sku_list):
    spot_skus = [s for s in sku_list if s["usage_type"] in ["Preemptible", "Spot"]]
    return spot_skus[0]["price"] if spot_skus else None

# Extract cheapest on-demand price
def get_standard_price(sku_list):
    ondemand_skus = [s for s in sku_list if s["usage_type"] == "OnDemand"]
    return ondemand_skus[0]["price"] if ondemand_skus else None

# Extract 1-year commitment price
def get_commitment_1yr_price(sku_list):
    commit_skus = [s for s in sku_list
                   if "1 Year" in s["description"] or "1yr" in s["description"].lower()]
    return commit_skus[0]["price"] if commit_skus else None

# Extract 3-year commitment price
def get_commitment_3yr_price(sku_list):
    commit_skus = [s for s in sku_list
                   if "3 Year" in s["description"] or "3yr" in s["description"].lower()]
    return commit_skus[0]["price"] if commit_skus else None

# Get all available pricing tiers with names
def all_prices(sku_list):
    options = []

    # Spot/Preemptible
    spot = get_spot_price(sku_list)
    if spot:
        options.append({
            "name": "Spot (Preemptible)",
            "price": spot,
            "description": ...,
            "sku_id": ...,
            "usage_type": ...
        })

    # On-Demand, 1-Year, 3-Year
    # ... (same pattern)

    return options
```

---

## Complete Code Flows

### Flow 1: Full Setup â†’ Launch â†’ Pricing Usage

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ User: python training/cli.py setup                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SETUP PHASE (training/cli/setup/pricing_setup.py:96)               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚ Step 1: Create Repository                                          â”‚
â”‚   gcloud artifacts repositories create arr-coc-pricing              â”‚
â”‚   â†’ us-central1-generic.pkg.dev/PROJECT/arr-coc-pricing             â”‚
â”‚                                                                     â”‚
â”‚ Step 2: Grant OIDC Permissions (silent)                            â”‚
â”‚   gcloud iam service-accounts add-iam-policy-binding               â”‚
â”‚   â†’ roles/iam.serviceAccountUser granted                           â”‚
â”‚                                                                     â”‚
â”‚ Step 3: Deploy Cloud Function                                      â”‚
â”‚   gcloud functions deploy arr-coc-pricing-runner                   â”‚
â”‚   â†’ Gen2, Python 3.12, 512MB, 540s timeout                         â”‚
â”‚   â†’ Entry point: fetch_pricing()                                   â”‚
â”‚                                                                     â”‚
â”‚ Step 4: Bootstrap Pricing                                          â”‚
â”‚   Try fetch from Artifact Registry                                 â”‚
â”‚   â†’ Not found                                                       â”‚
â”‚   Fetch from GCP Billing API                                       â”‚
â”‚   â†’ Query ~30,000 SKUs                                              â”‚
â”‚   â†’ Filter: C3, E2, GPUs                                            â”‚
â”‚   â†’ Sort by price (cheapest first)                                 â”‚
â”‚   Upload to Artifact Registry                                      â”‚
â”‚   â†’ Version: 1.0.20251116-143052                                   â”‚
â”‚   Trigger Cloud Function (first run)                               â”‚
â”‚   â†’ Watch logs for "PRICING_RUNNER_STARTED"                        â”‚
â”‚                                                                     â”‚
â”‚ Step 5: Create Scheduler                                           â”‚
â”‚   gcloud scheduler jobs create http arr-coc-pricing-scheduler      â”‚
â”‚   â†’ Schedule: */20 * * * * (every 20 min)                          â”‚
â”‚   â†’ Trigger: Cloud Function HTTP endpoint                          â”‚
â”‚   â†’ Auth: OIDC with service account                                â”‚
â”‚                                                                     â”‚
â”‚ âœ“ Pricing infrastructure deployed                                  â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
                   [20 minutes pass]
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AUTOMATIC PRICING UPDATE (Cloud Scheduler â†’ Function)              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚ Cloud Scheduler triggers:                                          â”‚
â”‚   HTTP GET â†’ arr-coc-pricing-runner function URL                   â”‚
â”‚   Auth: OIDC token from service account                            â”‚
â”‚                                                                     â”‚
â”‚ Cloud Function executes:                                           â”‚
â”‚   fetch_pricing() - same logic as bootstrap                        â”‚
â”‚   â†’ Fetch ~30,000 SKUs from GCP Billing API                        â”‚
â”‚   â†’ Filter, categorize, sort                                       â”‚
â”‚   â†’ Upload to Artifact Registry                                    â”‚
â”‚   â†’ New version: 1.0.20251116-145052                               â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
                 [User launches training]
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ User: python training/cli.py launch                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LAUNCH PHASE (training/cli/launch/core.py:750)                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚ [Line 815] Auto-request GPU quota                                  â”‚
â”‚   _auto_request_gpu_quota(config, region, status)                  â”‚
â”‚   â†’ Check Compute Engine quota (approximation)                     â”‚
â”‚   â†’ If zero, auto-request Vertex AI quota                          â”‚
â”‚   â†’ Return: "EXISTS" (proceed)                                     â”‚
â”‚                                                                     â”‚
â”‚ [Line 804] Handle base image build                                 â”‚
â”‚   _handle_base_image(config, region, status)                       â”‚
â”‚   â†’ Build ML libraries image                                       â”‚
â”‚                                                                     â”‚
â”‚ [Line 808] Build training image                                    â”‚
â”‚   _handle_training_image(config, region, status)                   â”‚
â”‚   â†’ Uses pricing for cost tracking:                                â”‚
â”‚       get_live_price_for_launch("E2_HIGHCPU_8", "us-west2")        â”‚
â”‚       â”œâ”€ fetch_pricing_no_save()                                   â”‚
â”‚       â”‚   â”œâ”€ HTTP: Get latest version from Artifact Registry       â”‚
â”‚       â”‚   â”œâ”€ gcloud: Download pricing JSON to temp                 â”‚
â”‚       â”‚   â””â”€ Return: (pricing_data, version, size_kb)              â”‚
â”‚       â”œâ”€ Extract E2 on-demand pricing                              â”‚
â”‚       â”‚   cpu_price = get_standard_price(cpu_skus)                 â”‚
â”‚       â”‚   ram_price = get_standard_price(ram_skus)                 â”‚
â”‚       â””â”€ Calculate: (8 Ã— cpu_price) + (8 Ã— ram_price)              â”‚
â”‚                                                                     â”‚
â”‚ [During MECHA battle animations]                                   â”‚
â”‚   mecha_battle_epic.py uses pricing for display:                   â”‚
â”‚   get_spot_price(cpu_skus)                                         â”‚
â”‚   â†’ Display: "âš¡ C3 SPOT PRICE: $0.012/core/hr âš¡"                  â”‚
â”‚                                                                     â”‚
â”‚ [Continue with job submission...]                                  â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Flow 2: Pricing Data Journey (Birth to Usage)

```
                    PRICING DATA LIFECYCLE

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ BIRTH: GCP Cloud Billing API                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚ Source: https://cloudbilling.googleapis.com/v1/                    â”‚
â”‚         services/6F81-5844-456A/skus                                â”‚
â”‚                                                                     â”‚
â”‚ Data volume: ~30,000 SKUs                                          â”‚
â”‚ Pagination: 500 SKUs per page                                      â”‚
â”‚ Fields per SKU:                                                     â”‚
â”‚   {                                                                 â”‚
â”‚     "skuId": "...",                                                 â”‚
â”‚     "description": "Spot Preemptible Nvidia Tesla T4 GPU ...",     â”‚
â”‚     "category": {"usageType": "Preemptible"},                      â”‚
â”‚     "serviceRegions": ["us-central1", ...],                        â”‚
â”‚     "pricingInfo": [{                                              â”‚
â”‚       "pricingExpression": {                                       â”‚
â”‚         "tieredRates": [{                                          â”‚
â”‚           "unitPrice": {                                           â”‚
â”‚             "units": "0",                                          â”‚
â”‚             "nanos": 140000000  # $0.14/hour                       â”‚
â”‚           }                                                         â”‚
â”‚         }]                                                          â”‚
â”‚       }                                                             â”‚
â”‚     }]                                                              â”‚
â”‚   }                                                                 â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
            _fetch_pricing_inline() processes
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ TRANSFORMATION: Categorize & Structure                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚ pricing_data = {                                                    â”‚
â”‚   "updated": "2025-11-16T14:30:52Z",                                â”‚
â”‚   "c3_machines": {                                                  â”‚
â”‚     "us-central1": {                                                â”‚
â”‚       "cpu_per_core_spot": [                                        â”‚
â”‚         {                                                           â”‚
â”‚           "price": 0.01234,                                         â”‚
â”‚           "description": "Compute optimized Core...",               â”‚
â”‚           "sku_id": "...",                                          â”‚
â”‚           "usage_type": "Preemptible"                               â”‚
â”‚         },                                                          â”‚
â”‚         # ... more SKUs, sorted by price (cheapest first)          â”‚
â”‚       ],                                                            â”‚
â”‚       "ram_per_gb_spot": [...]                                      â”‚
â”‚     },                                                              â”‚
â”‚     "us-west2": {...},                                              â”‚
â”‚     # ... all GCP regions                                           â”‚
â”‚   },                                                                â”‚
â”‚   "e2_machines": {                                                  â”‚
â”‚     "us-central1": {                                                â”‚
â”‚       "cpu_per_core_ondemand": [...],                               â”‚
â”‚       "ram_per_gb_ondemand": [...]                                  â”‚
â”‚     },                                                              â”‚
â”‚     # ... all regions                                               â”‚
â”‚   },                                                                â”‚
â”‚   "gpus_spot": {                                                    â”‚
â”‚     "us-central1": [                                                â”‚
â”‚       {                                                             â”‚
â”‚         "price": 0.14,                                              â”‚
â”‚         "description": "Nvidia Tesla T4 GPU attached to...",        â”‚
â”‚         "sku_id": "...",                                            â”‚
â”‚         "usage_type": "Spot"                                        â”‚
â”‚       },                                                            â”‚
â”‚       # ... T4, L4, V100, P4, P100, A100, H100, H200                â”‚
â”‚     ],                                                              â”‚
â”‚     # ... all regions                                               â”‚
â”‚   },                                                                â”‚
â”‚   "gpus_ondemand": {                                                â”‚
â”‚     "us-central1": [                                                â”‚
â”‚       # OnDemand pricing                                            â”‚
â”‚       {"price": 0.35, "usage_type": "OnDemand", ...},               â”‚
â”‚       # 1-Year commitment pricing                                   â”‚
â”‚       {"price": 0.245, "usage_type": "Commit", "description": "... 1 Year Commitment", ...},â”‚
â”‚       # 3-Year commitment pricing                                   â”‚
â”‚       {"price": 0.175, "usage_type": "Commit", "description": "... 3 Year Commitment", ...},â”‚
â”‚     ],                                                              â”‚
â”‚     # ... all regions                                               â”‚
â”‚   }                                                                 â”‚
â”‚ }                                                                   â”‚
â”‚                                                                     â”‚
â”‚ File size: ~180 KB (JSON)                                           â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
        upload_pricing_to_artifact_registry()
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STORAGE: Artifact Registry (Generic Repository)                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚ Repository: us-central1-generic.pkg.dev/                           â”‚
â”‚             weight-and-biases-476906/                               â”‚
â”‚             arr-coc-pricing                                         â”‚
â”‚                                                                     â”‚
â”‚ Package: gcp-pricing                                                â”‚
â”‚                                                                     â”‚
â”‚ Versions: (timestamp-based, immutable)                              â”‚
â”‚   1.0.20251116-143052  (180 KB)  â† Latest                          â”‚
â”‚   1.0.20251116-141052  (180 KB)                                    â”‚
â”‚   1.0.20251116-135052  (180 KB)                                    â”‚
â”‚   1.0.20251116-133052  (179 KB)                                    â”‚
â”‚   # ... historical versions preserved                               â”‚
â”‚                                                                     â”‚
â”‚ Retention: Indefinite (historical data preserved)                   â”‚
â”‚ Access: HTTP API + gcloud CLI                                      â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
            Consumer code fetches
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CONSUMPTION: Multiple Consumer Patterns                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚ Consumer 1: MECHA Battle Epic                                      â”‚
â”‚   File: training/cli/launch/mecha/mecha_battle_epic.py:258         â”‚
â”‚   Usage:                                                            â”‚
â”‚     from ...shared.artifact_pricing import get_spot_price          â”‚
â”‚     cpu_price = get_spot_price(pricing["c3_machines"]["us-west2"]["cpu_per_core_spot"])â”‚
â”‚     â†’ Display: "âš¡ C3 SPOT: $0.012/core/hr âš¡"                       â”‚
â”‚                                                                     â”‚
â”‚ Consumer 2: Launch Core (Build Cost Tracking)                      â”‚
â”‚   File: training/cli/shared/pricing/get_live_prices.py:10          â”‚
â”‚   Usage:                                                            â”‚
â”‚     price = get_live_price_for_launch("c3-standard-176", "us-west2")â”‚
â”‚     â†’ Calculate: (176 cores Ã— $0.012) + (704 GB Ã— $0.002)          â”‚
â”‚     â†’ Result: $2.11/hour                                            â”‚
â”‚     â†’ Stored in campaign stats JSON                                â”‚
â”‚                                                                     â”‚
â”‚ Consumer 3: Generic Price Extraction                               â”‚
â”‚   File: training/cli/shared/artifact_pricing.py:229-397            â”‚
â”‚   Functions:                                                        â”‚
â”‚     â€¢ get_spot_price(sku_list) â†’ Cheapest spot                     â”‚
â”‚     â€¢ get_standard_price(sku_list) â†’ Cheapest on-demand            â”‚
â”‚     â€¢ get_commitment_1yr_price(sku_list) â†’ 1-year commit           â”‚
â”‚     â€¢ get_commitment_3yr_price(sku_list) â†’ 3-year commit           â”‚
â”‚     â€¢ all_prices(sku_list) â†’ All tiers with metadata               â”‚
â”‚                                                                     â”‚
â”‚ Access Pattern (all consumers):                                    â”‚
â”‚   1. Call: fetch_pricing_no_save()                                 â”‚
â”‚      â”œâ”€ HTTP: Get latest version                                   â”‚
â”‚      â”œâ”€ gcloud: Download to temp                                   â”‚
â”‚      â””â”€ Return: (pricing_data, version, size_kb)                   â”‚
â”‚   2. Extract relevant data structure                               â”‚
â”‚   3. Call price helper functions                                   â”‚
â”‚   4. Use price in calculations/display                             â”‚
â”‚                                                                     â”‚
â”‚ Note: NO local caching! Always fetch from Artifact Registry.       â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Flow 3: Quota Check Decision Tree

```
                    GPU QUOTA DECISION FLOW

User: python training/cli.py launch
                â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Read config from .training file                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚ WANDB_LAUNCH_ACCELERATOR_TYPE = "NVIDIA_TESLA_T4"                  â”‚
â”‚ WANDB_LAUNCH_ACCELERATOR_COUNT = "1"                               â”‚
â”‚ WANDB_LAUNCH_USE_PREEMPTIBLE = "true"                              â”‚
â”‚ GCP_PROJECT_ID = "weight-and-biases-476906"                        â”‚
â”‚ GCP_ROOT_RESOURCE_REGION = "us-central1"                           â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â†“
        _auto_request_gpu_quota(config, region, status)
                â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 1: Map GPU type to quota metrics                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚ Compute Engine metric (for quick check):                           â”‚
â”‚   "NVIDIA_TESLA_T4" â†’ "NVIDIA_T4_GPUS"                              â”‚
â”‚   + use_preemptible â†’ "PREEMPTIBLE_NVIDIA_T4_GPUS"                 â”‚
â”‚                                                                     â”‚
â”‚ Vertex AI metric (for auto-request):                               â”‚
â”‚   "NVIDIA_TESLA_T4" â†’ "nvidia_t4_gpus"                              â”‚
â”‚   â†’ "aiplatform.googleapis.com/custom_model_training_nvidia_t4_gpus"â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 2: Quick check Compute Engine quota                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚ gcloud compute regions describe us-central1 --format=json          â”‚
â”‚                                                                     â”‚
â”‚ Response:                                                           â”‚
â”‚   {                                                                 â”‚
â”‚     "quotas": [                                                     â”‚
â”‚       {                                                             â”‚
â”‚         "metric": "PREEMPTIBLE_NVIDIA_T4_GPUS",                     â”‚
â”‚         "limit": 1.0,                                               â”‚
â”‚         "usage": 0.0                                                â”‚
â”‚       },                                                            â”‚
â”‚       ...                                                           â”‚
â”‚     ]                                                               â”‚
â”‚   }                                                                 â”‚
â”‚                                                                     â”‚
â”‚ Decision:                                                           â”‚
â”‚   if limit > 0:                                                     â”‚
â”‚       status("âœ“ T4 quota exists (limit: 1.0)")                     â”‚
â”‚       return "EXISTS" âœ“                                             â”‚
â”‚   else:                                                             â”‚
â”‚       # Quota is 0 - continue to auto-request                      â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â†“ (if limit == 0)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 3: Auto-request Vertex AI quota                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚ status("âš ï¸ T4 quota is 0 or doesn't exist")                        â”‚
â”‚ status("Attempting automatic quota request...")                    â”‚
â”‚                                                                     â”‚
â”‚ gcloud alpha compute regions update-quota                          â”‚
â”‚     --project=weight-and-biases-476906                             â”‚
â”‚     --region=us-central1                                           â”‚
â”‚     --quota-metric=aiplatform.googleapis.com/                      â”‚
â”‚                    custom_model_training_nvidia_t4_gpus            â”‚
â”‚     --new-limit=1                                                  â”‚
â”‚                                                                     â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚ â”‚ SUCCESS                                                     â”‚   â”‚
â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”‚
â”‚ â”‚                                                             â”‚   â”‚
â”‚ â”‚ status("âœ… T4 QUOTA REQUEST SUBMITTED!")                   â”‚   â”‚
â”‚ â”‚ status("   GPU Type: NVIDIA_TESLA_T4")                     â”‚   â”‚
â”‚ â”‚ status("   Requested: 1 GPU(s)")                           â”‚   â”‚
â”‚ â”‚ status("   Region: us-central1")                           â”‚   â”‚
â”‚ â”‚ status("ğŸ“§ Google will email when approved (1-2 days)")    â”‚   â”‚
â”‚ â”‚                                                             â”‚   â”‚
â”‚ â”‚ return "REQUESTED"  â†’ HALT LAUNCH!                         â”‚   â”‚
â”‚ â”‚                                                             â”‚   â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                     â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚ â”‚ FAILURE                                                     â”‚   â”‚
â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”‚
â”‚ â”‚                                                             â”‚   â”‚
â”‚ â”‚ status("âš ï¸ Auto-request failed")                            â”‚   â”‚
â”‚ â”‚ status(f"Error: {stderr[:200]}")                           â”‚   â”‚
â”‚ â”‚ status("Proceeding to quota verification...")             â”‚   â”‚
â”‚ â”‚                                                             â”‚   â”‚
â”‚ â”‚ return "FAILED"  â†’ Continue launch                         â”‚   â”‚
â”‚ â”‚                                                             â”‚   â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LAUNCH DECISION (training/cli/launch/core.py:816)                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚ quota_status = _auto_request_gpu_quota(...)                        â”‚
â”‚                                                                     â”‚
â”‚ if quota_status == "REQUESTED":                                    â”‚
â”‚     status("ğŸ›‘ LAUNCH HALTED - awaiting quota approval")           â”‚
â”‚     status("Next steps:")                                          â”‚
â”‚     status("1. Wait 1-2 business days")                            â”‚
â”‚     status("2. Check email for approval")                          â”‚
â”‚     status("3. Run launch again")                                  â”‚
â”‚     return False  # ABORT! âœ‹                                       â”‚
â”‚                                                                     â”‚
â”‚ elif quota_status == "EXISTS":                                     â”‚
â”‚     # Proceed with launch âœ“                                        â”‚
â”‚     [Continue to Step 2: Submit to W&B queue...]                   â”‚
â”‚                                                                     â”‚
â”‚ elif quota_status == "FAILED":                                     â”‚
â”‚     # Auto-request didn't work, but continue anyway                â”‚
â”‚     # User might have manually requested quota earlier             â”‚
â”‚     # If quota truly missing, Vertex AI will reject later          â”‚
â”‚     [Continue to Step 2: Submit to W&B queue...]                   â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â†“ (if continuing)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Vertex AI Job Submission (Eventually)                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚ If quota truly missing:                                             â”‚
â”‚   ERROR: grpc._channel._InactiveRpcError                           â”‚
â”‚   status = StatusCode.RESOURCE_EXHAUSTED                           â”‚
â”‚   details = "The following quota metrics exceed quota limits:      â”‚
â”‚              aiplatform.googleapis.com/                            â”‚
â”‚              custom_model_training_nvidia_t4_gpus"                 â”‚
â”‚                                                                     â”‚
â”‚ Wrapper catches error â†’ Logs to Cloud Logging â†’ Monitor extracts   â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Data Structures

### Pricing Data Structure (Complete Schema)

```json
{
  "updated": "2025-11-16T14:30:52Z",

  "c3_machines": {
    "us-central1": {
      "cpu_per_core_spot": [
        {
          "price": 0.01234,
          "description": "Compute optimized Core running in Americas",
          "sku_id": "XXXX-YYYY-ZZZZ",
          "usage_type": "Preemptible"
        }
      ],
      "ram_per_gb_spot": [
        {
          "price": 0.00165,
          "description": "Compute optimized Ram running in Americas",
          "sku_id": "AAAA-BBBB-CCCC",
          "usage_type": "Preemptible"
        }
      ]
    },
    "us-west2": { /* same structure */ },
    /* ... all GCP regions ... */
  },

  "e2_machines": {
    "us-central1": {
      "cpu_per_core_ondemand": [
        {
          "price": 0.0218,
          "description": "E2 Instance Core running in Americas",
          "sku_id": "...",
          "usage_type": "OnDemand"
        }
      ],
      "ram_per_gb_ondemand": [
        {
          "price": 0.00292,
          "description": "E2 Instance Ram running in Americas",
          "sku_id": "...",
          "usage_type": "OnDemand"
        }
      ]
    },
    /* ... all regions ... */
  },

  "gpus_spot": {
    "us-central1": [
      {
        "price": 0.14,
        "description": "Nvidia Tesla T4 GPU attached to Spot Preemptible VMs running in Americas",
        "sku_id": "...",
        "usage_type": "Spot"
      },
      {
        "price": 0.22,
        "description": "Nvidia L4 GPU attached to Spot Preemptible VMs running in Americas",
        "sku_id": "...",
        "usage_type": "Preemptible"
      }
      /* T4, L4, V100, P4, P100, A100, H100, H200 */
    ],
    /* ... all regions ... */
  },

  "gpus_ondemand": {
    "us-central1": [
      {
        "price": 0.35,
        "description": "Nvidia Tesla T4 GPU attached to VMs running in Americas",
        "sku_id": "...",
        "usage_type": "OnDemand"
      },
      {
        "price": 0.245,
        "description": "Commitment v1: Nvidia Tesla T4 GPU attached to VMs running in Americas for 1 Year",
        "sku_id": "...",
        "usage_type": "Commit"
      },
      {
        "price": 0.175,
        "description": "Commitment v1: Nvidia Tesla T4 GPU attached to VMs running in Americas for 3 Year",
        "sku_id": "...",
        "usage_type": "Commit"
      }
      /* OnDemand + 1-Year + 3-Year for all GPU types */
    ],
    /* ... all regions ... */
  }
}
```

**Key Properties**:
1. **Sorted**: All SKU lists sorted by price (cheapest first)
2. **Complete**: All pricing tiers included (spot, on-demand, 1yr, 3yr)
3. **Metadata**: Full SKU data preserved (description, ID, usage type)
4. **Immutable**: Each version timestamped, never modified

### Config Data Structure (.training file)

```bash
# GPU Configuration
WANDB_LAUNCH_ACCELERATOR_TYPE=NVIDIA_TESLA_T4
WANDB_LAUNCH_ACCELERATOR_COUNT=1
WANDB_LAUNCH_USE_PREEMPTIBLE=true

# Project Configuration
GCP_PROJECT_ID=weight-and-biases-476906
GCP_ROOT_RESOURCE_REGION=us-central1

# Machine Configuration
WANDB_LAUNCH_MACHINE_TYPE=n1-standard-4
```

---

## Configuration & Constants

### Pricing Configuration

**File**: `training/cli/shared/pricing_config.py`

| Constant | Value | Purpose |
|----------|-------|---------|
| `PROJECT_ID` | `"weight-and-biases-476906"` | GCP project (from .training) |
| `REGION` | `"us-central1"` | Default region (from .training) |
| `FUNCTION_NAME` | `"arr-coc-pricing-runner"` | Cloud Function name |
| `SCHEDULER_JOB` | `"arr-coc-pricing-scheduler"` | Scheduler job name |
| `SCHEDULER_INTERVAL_MINUTES` | `20` | Update frequency (every 20 min) |
| `REPOSITORY` | `"arr-coc-pricing"` | Artifact Registry repo |
| `PACKAGE` | `"gcp-pricing"` | Package name in repo |

### GPU Quota Maps

**File**: `training/cli/launch/core.py:3937-3945, 3996-4004`

**Vertex AI Quota Metrics** (Auto-Request):
```python
gpu_quota_metrics = {
    "NVIDIA_TESLA_T4": "nvidia_t4_gpus",
    "NVIDIA_TESLA_A100": "nvidia_a100_gpus",
    "NVIDIA_A100_80GB": "nvidia_a100_80gb_gpus",
    "NVIDIA_H100": "nvidia_h100_gpus",
    "NVIDIA_H100_80GB": "nvidia_h100_80gb_gpus",
    "NVIDIA_H200": "nvidia_h200_gpus",
    "NVIDIA_L4": "nvidia_l4_gpus",
}
# â†’ "aiplatform.googleapis.com/custom_model_training_{suffix}"
```

**Compute Engine Quota Metrics** (Quick Check):
```python
quota_map = {
    "NVIDIA_H200": "NVIDIA_H200_GPUS",
    "NVIDIA_H100": "NVIDIA_H100_GPUS",
    "NVIDIA_H100_80GB": "NVIDIA_H100_80GB_GPUS",
    "NVIDIA_A100_80GB": "NVIDIA_A100_80GB_GPUS",
    "NVIDIA_TESLA_A100": "NVIDIA_A100_GPUS",
    "NVIDIA_TESLA_T4": "NVIDIA_T4_GPUS",
    "NVIDIA_L4": "NVIDIA_L4_GPUS",
}
# + "PREEMPTIBLE_" prefix if use_spot == true
```

---

## Error Handling Patterns

### Retry Logic (Shared Pattern)

**File**: `training/cli/shared/retry.py`

```python
# Retry delays (fuck it, restart pattern)
RETRY_DELAYS = [0, 1, 4, 8]  # 0s, 1s, 4s, 8s
MAX_ATTEMPTS = 4

def retry_with_backoff(operation_func, max_attempts=4, operation_name="operation"):
    """
    Retry with fixed backoff: 0s, 1s, 4s, 8s (cloud-optimized).

    Args:
        operation_func: Function returning (success: bool, error_msg: str)
        max_attempts: Max retry attempts
        operation_name: Name for logging

    Returns:
        (success: bool, error_msg: str or None)
    """
    for attempt in range(1, max_attempts + 1):
        success, error_msg = operation_func()

        if success:
            return (True, None)

        if attempt < max_attempts:
            delay = RETRY_DELAYS[attempt]
            time.sleep(delay)
        else:
            return (False, error_msg)

    return (False, "Max retries exceeded")
```

**Used By**:
- Pricing setup: `grant_actAs_permission()` (4 attempts)
- Pricing setup: `deploy_cloud_function()` (4 attempts)
- Pricing teardown: `delete_scheduler()` (4 attempts)
- Pricing teardown: `delete_cloud_function()` (4 attempts)

### Idempotency Patterns

**Pattern 1: Check Before Create**
```python
# Check if resource exists
result = subprocess.run(["gcloud", "...", "describe", resource_name], ...)
if result.returncode == 0:
    return  # Already exists, skip creation (idempotent)

# Create resource
subprocess.run(["gcloud", "...", "create", resource_name], ...)
```

**Pattern 2: Ignore "Already Exists" Errors**
```python
result = subprocess.run(["gcloud", "...", "create", resource_name], ...)

if result.returncode == 0:
    return (True, None)

# Check if error is "already exists"
if "already has" in result.stderr.lower() or "already exists" in result.stderr.lower():
    return (True, None)  # Idempotent success

return (False, error_msg)  # Real error
```

**Pattern 3: Ignore "Not Found" Errors**
```python
result = subprocess.run(["gcloud", "...", "delete", resource_name], ...)

if result.returncode == 0:
    return (True, None)

# Check if error is "not found"
stderr_lower = result.stderr.lower()
if "not found" in stderr_lower or "not_found" in stderr_lower:
    return (True, None)  # Already deleted, idempotent success

return (False, error_msg)  # Real error
```

---

## Quick Reference Tables

### File Locations Quick Reference

| Component | File | Lines | Purpose |
|-----------|------|-------|---------|
| **GPU Quotas** |
| Auto-request function | `training/cli/launch/core.py` | 3913-4083 | Check/request GPU quotas |
| Launch integration | `training/cli/launch/core.py` | 815-830 | Use quota check results |
| Manual instructions (unused) | `training/cli/shared/gpu_quota_instruct.py` | 97-153 | Show manual request steps |
| **GPU Pricing** |
| Pricing config | `training/cli/shared/pricing_config.py` | 1-78 | Constants & schema |
| Setup infrastructure | `training/cli/setup/pricing_setup.py` | 96-1050 | Create pricing system |
| Teardown infrastructure | `training/cli/teardown/pricing_teardown.py` | 95-284 | Delete pricing system |
| Artifact Registry ops | `training/cli/shared/artifact_pricing.py` | 1-398 | Fetch/upload pricing |
| Live price calculator | `training/cli/shared/pricing/get_live_prices.py` | 10-58 | Calculate build costs |
| MECHA pricing display | `training/cli/launch/mecha/mecha_battle_epic.py` | 258, 288 | Battle animations |
| Cloud Function | `training/cli/shared/pricing/cloud_function/main.py` | 1-600+ | Fetch pricing (deployed) |

### Function Call Chains

**Launch â†’ GPU Quota Check**:
```
launch_training_job()  (core.py:750)
â””â”€â†’ _auto_request_gpu_quota()  (core.py:3913)
    â”œâ”€â†’ gcloud compute regions describe  (check CE quota)
    â””â”€â†’ gcloud alpha compute regions update-quota  (request VA quota)
```

**Setup â†’ Pricing Infrastructure**:
```
setup_pricing_infrastructure()  (pricing_setup.py:96)
â”œâ”€â†’ create_pricing_repository()  (pricing_setup.py:125)
â”œâ”€â†’ grant_actAs_permission()  (pricing_setup.py:599)
â”‚   â””â”€â†’ retry_with_backoff()  (retry.py)
â”œâ”€â†’ deploy_cloud_function()  (pricing_setup.py:703)
â”‚   â””â”€â†’ retry_with_backoff()  (retry.py)
â”œâ”€â†’ bootstrap_pricing()  (pricing_setup.py:167)
â”‚   â”œâ”€â†’ fetch_pricing_no_save()  (artifact_pricing.py:96)
â”‚   â”‚   â”œâ”€â†’ _get_latest_version()  (artifact_pricing.py:60)
â”‚   â”‚   â””â”€â†’ gcloud artifacts generic download
â”‚   â”œâ”€â†’ get_pricing_age_minutes()  (artifact_pricing.py:199)
â”‚   â”œâ”€â†’ _fetch_pricing_inline()  (pricing_setup.py:317)
â”‚   â”‚   â””â”€â†’ Query GCP Billing API (~30K SKUs)
â”‚   â”œâ”€â†’ upload_pricing_to_artifact_registry()  (artifact_pricing.py:160)
â”‚   â”‚   â””â”€â†’ gcloud artifacts generic upload
â”‚   â””â”€â†’ _trigger_and_verify_function()  (pricing_setup.py:527)
â””â”€â†’ create_scheduler()  (pricing_setup.py:883)
```

**Launch â†’ Pricing Usage**:
```
_handle_training_image()  (core.py:808)
â””â”€â†’ get_live_price_for_launch()  (get_live_prices.py:10)
    â”œâ”€â†’ fetch_pricing_no_save()  (artifact_pricing.py:96)
    â”œâ”€â†’ get_spot_price()  (artifact_pricing.py:229)
    â””â”€â†’ get_standard_price()  (artifact_pricing.py:251)
```

### GCloud Commands Used

**GPU Quotas**:
```bash
# Check Compute Engine quota (quick approximation)
gcloud compute regions describe us-central1 --format=json

# Auto-request Vertex AI quota
gcloud alpha compute regions update-quota \
    --project=PROJECT \
    --region=us-central1 \
    --quota-metric=aiplatform.googleapis.com/custom_model_training_nvidia_t4_gpus \
    --new-limit=1
```

**Pricing Infrastructure**:
```bash
# Create repository
gcloud artifacts repositories create arr-coc-pricing \
    --repository-format=generic \
    --location=us-central1

# Deploy Cloud Function
gcloud functions deploy arr-coc-pricing-runner \
    --gen2 \
    --region=us-central1 \
    --runtime=python312 \
    --entry-point=fetch_pricing \
    --trigger-http \
    --timeout=540s \
    --memory=512MB

# Create scheduler
gcloud scheduler jobs create http arr-coc-pricing-scheduler \
    --location=us-central1 \
    --schedule="*/20 * * * *" \
    --uri=FUNCTION_URL \
    --oidc-service-account-email=SA_EMAIL

# Upload pricing
gcloud artifacts generic upload \
    --package=gcp-pricing \
    --version=1.0.20251116-143052 \
    --source=pricing.json

# Download pricing
gcloud artifacts generic download \
    --package=gcp-pricing \
    --version=1.0.20251116-143052 \
    --destination=/tmp
```

### API Endpoints Used

**Vertex AI Quotas**:
- Not directly accessed (uses `gcloud alpha compute regions update-quota`)

**Artifact Registry**:
```
GET https://artifactregistry.googleapis.com/v1/
    projects/{PROJECT}/locations/{LOCATION}/repositories/{REPO}/
    packages/{PACKAGE}/versions
    ?pageSize=1&orderBy=createTime desc

â†’ Returns latest pricing version
```

**GCP Cloud Billing**:
```
GET https://cloudbilling.googleapis.com/v1/
    services/6F81-5844-456A/skus
    ?pageSize=500

â†’ Returns ~30,000 pricing SKUs (paginated)
```

---

## ğŸ” Where Do I Find...?

**Q: Where is GPU quota checking logic?**
â†’ `training/cli/launch/core.py:3913` (`_auto_request_gpu_quota()`)

**Q: Where does launch use quota check results?**
â†’ `training/cli/launch/core.py:815-830`

**Q: Where is pricing infrastructure setup?**
â†’ `training/cli/setup/pricing_setup.py:96` (`setup_pricing_infrastructure()`)

**Q: Where is pricing infrastructure teardown?**
â†’ `training/cli/teardown/pricing_teardown.py:95` (`teardown_pricing_infrastructure()`)

**Q: Where does MECHA get spot prices?**
â†’ `training/cli/launch/mecha/mecha_battle_epic.py:258, 288` (uses `get_spot_price()`)

**Q: Where are pricing packages stored?**
â†’ Artifact Registry: `us-central1-generic.pkg.dev/.../arr-coc-pricing/gcp-pricing`

**Q: Where is the Cloud Function code?**
â†’ `training/cli/shared/pricing/cloud_function/main.py`

**Q: Where is live price calculation?**
â†’ `training/cli/shared/pricing/get_live_prices.py:10` (`get_live_price_for_launch()`)

**Q: Where are pricing helper functions?**
â†’ `training/cli/shared/artifact_pricing.py:229-397`

**Q: Where is pricing schema defined?**
â†’ `training/cli/shared/pricing_config.py:63-69` (`PRICING_SCHEMA`)

**Q: Where is retry logic?**
â†’ `training/cli/shared/retry.py` (shared by setup/teardown)

**Q: Is there any user-facing pricing?**
â†’ **NO** - All user-facing pricing displays deleted 2025-11-16

**Q: What happened to the old GPU quota verification?**
â†’ **DELETED** - `_verify_gpu_quota()` removed 2025-11-16 (checked wrong quotas)

**Q: What happened to check_and_update_pricing()?**
â†’ **DELETED** - `mecha_battle_epic.py:275-359` removed 2025-11-16 (manual trigger logic, 24-hour staleness checks)
â†’ **Replaced with**: THE GOOD PRICING WAY - `fetch_pricing_no_save()` only (Cloud Scheduler handles refresh)

---

## Summary

This system map provides complete technical details for:

1. **GPU Quota System**: Infrastructure validation before Vertex AI launch
2. **GPU Pricing System**: Cost tracking with Cloud Function + Artifact Registry
3. **Complete Code Flows**: Step-by-step execution with line numbers
4. **Data Structures**: Pricing JSON schema, config files
5. **Error Handling**: Retry patterns, idempotency
6. **Quick Reference**: File locations, function chains, gcloud commands

**Key Insights**:
- Two **separate** quota namespaces (Compute Engine vs Vertex AI)
- Pricing stored in Artifact Registry (no local caching)
- Auto-request uses **correct** Vertex AI quotas
- Old verification deleted (checked wrong quotas)
- Infrastructure tracking only (no user-facing cost estimates)

---

**Last Updated**: 2025-11-16
**Version**: 2.0 - Complete code flow analysis
**Prepared by**: THE-PATTERN-PERFECTIONIST ğŸ¯
